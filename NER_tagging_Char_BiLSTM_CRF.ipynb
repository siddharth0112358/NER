{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/patsnap/anaconda2/lib/python3.7/site-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "\n",
    "from itertools import chain\n",
    "from collections import Counter\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile = '/Users/patsnap/Desktop/Neo4J_and_other_codes/1014-4361-bundle-archive/ner_dataset.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(datafile, encoding=\"latin1\", error_bad_lines=False)\n",
    "df = df.fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence #           Word  POS Tag\n",
       "0  Sentence: 1      Thousands  NNS   O\n",
       "1  Sentence: 1             of   IN   O\n",
       "2  Sentence: 1  demonstrators  NNS   O\n",
       "3  Sentence: 1           have  VBP   O\n",
       "4  Sentence: 1        marched  VBN   O"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1048575"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O',\n",
       " 'B-geo',\n",
       " 'B-gpe',\n",
       " 'B-per',\n",
       " 'I-geo',\n",
       " 'B-org',\n",
       " 'I-org',\n",
       " 'B-tim',\n",
       " 'B-art',\n",
       " 'I-art',\n",
       " 'I-per',\n",
       " 'I-gpe',\n",
       " 'I-tim',\n",
       " 'B-nat',\n",
       " 'B-eve',\n",
       " 'I-eve',\n",
       " 'I-nat']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = list(df.Tag.unique())\n",
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fd8505b4450>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "sns.countplot(df.Tag.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tags = len(tags)\n",
    "num_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_func = lambda s: [(w, t) for w, p, t in zip(s[\"Word\"].values.tolist(), s[\"POS\"].values.tolist(), s[\"Tag\"].values.tolist())]\n",
    "group = df.groupby(\"Sentence #\").apply(agg_func)\n",
    "lines = [s for s in group]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Thousands', 'O'),\n",
       " ('of', 'O'),\n",
       " ('demonstrators', 'O'),\n",
       " ('have', 'O'),\n",
       " ('marched', 'O'),\n",
       " ('through', 'O'),\n",
       " ('London', 'B-geo'),\n",
       " ('to', 'O'),\n",
       " ('protest', 'O'),\n",
       " ('the', 'O'),\n",
       " ('war', 'O'),\n",
       " ('in', 'O'),\n",
       " ('Iraq', 'B-geo'),\n",
       " ('and', 'O'),\n",
       " ('demand', 'O'),\n",
       " ('the', 'O'),\n",
       " ('withdrawal', 'O'),\n",
       " ('of', 'O'),\n",
       " ('British', 'B-gpe'),\n",
       " ('troops', 'O'),\n",
       " ('from', 'O'),\n",
       " ('that', 'O'),\n",
       " ('country', 'O'),\n",
       " ('.', 'O')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [['<START>'] + [tokens[0] for tokens in line] + ['<END>'] for line in lines]\n",
    "tags = [['<START>'] + [tokens[1] for tokens in line] + ['<END>'] for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = [[['<START']] + [['<START>'] + [ch for ch in word] + ['<END>'] for word in sent[1:-1]] + [['<END>']] for sent in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47959, 47959, 47959)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences), len(tags), len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<START>',\n",
       " 'Thousands',\n",
       " 'of',\n",
       " 'demonstrators',\n",
       " 'have',\n",
       " 'marched',\n",
       " 'through',\n",
       " 'London',\n",
       " 'to',\n",
       " 'protest',\n",
       " 'the',\n",
       " 'war',\n",
       " 'in',\n",
       " 'Iraq',\n",
       " 'and',\n",
       " 'demand',\n",
       " 'the',\n",
       " 'withdrawal',\n",
       " 'of',\n",
       " 'British',\n",
       " 'troops',\n",
       " 'from',\n",
       " 'that',\n",
       " 'country',\n",
       " '.',\n",
       " '<END>']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['<START'],\n",
       " ['<START>', 'T', 'h', 'o', 'u', 's', 'a', 'n', 'd', 's', '<END>'],\n",
       " ['<START>', 'o', 'f', '<END>'],\n",
       " ['<START>',\n",
       "  'd',\n",
       "  'e',\n",
       "  'm',\n",
       "  'o',\n",
       "  'n',\n",
       "  's',\n",
       "  't',\n",
       "  'r',\n",
       "  'a',\n",
       "  't',\n",
       "  'o',\n",
       "  'r',\n",
       "  's',\n",
       "  '<END>'],\n",
       " ['<START>', 'h', 'a', 'v', 'e', '<END>'],\n",
       " ['<START>', 'm', 'a', 'r', 'c', 'h', 'e', 'd', '<END>'],\n",
       " ['<START>', 't', 'h', 'r', 'o', 'u', 'g', 'h', '<END>'],\n",
       " ['<START>', 'L', 'o', 'n', 'd', 'o', 'n', '<END>'],\n",
       " ['<START>', 't', 'o', '<END>'],\n",
       " ['<START>', 'p', 'r', 'o', 't', 'e', 's', 't', '<END>'],\n",
       " ['<START>', 't', 'h', 'e', '<END>'],\n",
       " ['<START>', 'w', 'a', 'r', '<END>'],\n",
       " ['<START>', 'i', 'n', '<END>'],\n",
       " ['<START>', 'I', 'r', 'a', 'q', '<END>'],\n",
       " ['<START>', 'a', 'n', 'd', '<END>'],\n",
       " ['<START>', 'd', 'e', 'm', 'a', 'n', 'd', '<END>'],\n",
       " ['<START>', 't', 'h', 'e', '<END>'],\n",
       " ['<START>', 'w', 'i', 't', 'h', 'd', 'r', 'a', 'w', 'a', 'l', '<END>'],\n",
       " ['<START>', 'o', 'f', '<END>'],\n",
       " ['<START>', 'B', 'r', 'i', 't', 'i', 's', 'h', '<END>'],\n",
       " ['<START>', 't', 'r', 'o', 'o', 'p', 's', '<END>'],\n",
       " ['<START>', 'f', 'r', 'o', 'm', '<END>'],\n",
       " ['<START>', 't', 'h', 'a', 't', '<END>'],\n",
       " ['<START>', 'c', 'o', 'u', 'n', 't', 'r', 'y', '<END>'],\n",
       " ['<START>', '.', '<END>'],\n",
       " ['<END>']]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fd83a2ab750>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sen_lengths = [len(sent) for sent in sentences]\n",
    "plt.figure(figsize=(15, 5))\n",
    "sns.countplot(sen_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fd856b6e2d0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "char_lengths = [len(t) for char in chars for t in char]\n",
    "plt.figure(figsize=(15, 5))\n",
    "sns.countplot(char_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38367, 4796, 4796)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences, valid_sentences, train_tags, valid_tags, train_chars, valid_chars = train_test_split(sentences, tags, chars, test_size=0.2, random_state=42)\n",
    "valid_sentences, test_sentences, valid_tags, test_tags, valid_chars, test_chars = train_test_split(valid_sentences, valid_tags, valid_chars, test_size=0.5, random_state=42)\n",
    "len(train_sentences), len(valid_sentences), len(test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocab:\n",
    "    def __init__(self, word2id, id2word):\n",
    "        self.UNK = '<UNK>'\n",
    "        self.PAD = '<PAD>'\n",
    "        self.START = '<START>'\n",
    "        self.END = '<END>'\n",
    "        self.__word2id = word2id\n",
    "        self.__id2word = id2word\n",
    "\n",
    "    def get_word2id(self):\n",
    "        return self.__word2id\n",
    "\n",
    "    def get_id2word(self):\n",
    "        return self.__id2word\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        if self.UNK in self.__word2id:\n",
    "            return self.__word2id.get(item, self.__word2id[self.UNK])\n",
    "        return self.__word2id[item]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.__word2id)\n",
    "\n",
    "    def id2word(self, idx):\n",
    "        return self.__id2word[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(data, freq_cutoff=5, is_tags=False, is_chars=False):\n",
    "    if is_chars:\n",
    "        word_counts = Counter(chain(*chain(*train_chars[:10])))\n",
    "    else:\n",
    "        word_counts = Counter(chain(*data))\n",
    "    valid_words = [w for w, d in word_counts.items() if d >= freq_cutoff]\n",
    "    valid_words = sorted(valid_words, key=lambda x: word_counts[x], reverse=True)\n",
    "    valid_words += ['<PAD>']\n",
    "    word2id = {w: idx for idx, w in enumerate(valid_words)}\n",
    "    if not is_tags:\n",
    "        word2id['<UNK>'] = len(word2id)\n",
    "        valid_words += ['<UNK>']\n",
    "    return Vocab(word2id=word2id, id2word=valid_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_vocab = build_vocab(train_sentences)\n",
    "tags_vocab = build_vocab(train_tags, is_tags=True)\n",
    "chars_vocab = build_vocab(train_chars, is_chars=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9620, 20, 34)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words_vocab), len(tags_vocab), len(chars_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQ_LEN = 50\n",
    "MAX_WORD_LEN = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NERDataset(data.Dataset):\n",
    "    def __init__(self, sentences, tags, chars, max_seq_len, max_word_len):\n",
    "        self.sentences = sentences\n",
    "        self.tags = tags\n",
    "        self.characters = chars\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.max_word_len = max_word_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        sentence = self.sentences[item]\n",
    "        tag = self.tags[item]\n",
    "        chars = self.characters[item]\n",
    "        seq_len = len(sentence)\n",
    "\n",
    "        # convert the sentences and tags into numerical format\n",
    "        word_tokens = [words_vocab[word] for word in sentence]\n",
    "        tag_tokens = [tags_vocab[t] for t in tag]\n",
    "\n",
    "        char_seq = []\n",
    "        for word in chars:\n",
    "            word_len = len(word)\n",
    "            # truncate the word if it is greater than max_word_len\n",
    "            if word_len > self.max_word_len:\n",
    "                word = word[:self.max_word_len]\n",
    "            # pad the word if it less\n",
    "            else:\n",
    "                pad_length = self.max_word_len - word_len\n",
    "                word = word + [chars_vocab.PAD] * pad_length\n",
    "            \n",
    "            # convert the chars into numerical format\n",
    "            char_ids = []\n",
    "            for each_char in word: \n",
    "                char_ids.append(chars_vocab[each_char])\n",
    "            char_seq.append(char_ids)\n",
    "        \n",
    "        return torch.LongTensor(word_tokens), torch.LongTensor(char_seq), torch.LongTensor(tag_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = NERDataset(train_sentences, train_tags, train_chars, MAX_SEQ_LEN, MAX_WORD_LEN)\n",
    "valid_dataset = NERDataset(valid_sentences, valid_tags, valid_chars, MAX_SEQ_LEN, MAX_WORD_LEN)\n",
    "test_dataset = NERDataset(test_sentences, test_tags, test_chars, MAX_SEQ_LEN, MAX_WORD_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([   1,  150,  235,   11,   36,   72,   49, 3318,    8, 1977, 4171,  166,\n",
       "         9619, 9619, 7832,    4,  199,    7, 1385, 9619,   67, 1103,    3,    2]),\n",
       " tensor([[24, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32],\n",
       "         [ 1, 28,  4, 14,  5, 11,  0, 32, 32, 32, 32, 32, 32, 32, 32],\n",
       "         [ 1, 33,  4,  6,  2,  3,  0, 32, 32, 32, 32, 32, 32, 32, 32],\n",
       "         [ 1, 29,  7,  0, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32],\n",
       "         [ 1, 16,  4, 21,  2,  6,  8, 15,  2,  8,  5,  0, 32, 32, 32],\n",
       "         [ 1, 33, 14,  2,  7, 10,  3, 19,  0, 32, 32, 32, 32, 32, 32],\n",
       "         [ 1,  3, 12,  7,  4,  0, 32, 32, 32, 32, 32, 32, 32, 32, 32],\n",
       "         [ 1, 14,  8, 21,  2,  9, 12,  2, 10,  0, 32, 32, 32, 32, 32],\n",
       "         [ 1,  3,  0, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32],\n",
       "         [ 1,  7,  4, 33, 13,  3, 12, 12,  2, 10,  0, 32, 32, 32, 32],\n",
       "         [ 1, 33,  6,  2,  2,  8,  0, 32, 32, 32, 32, 32, 32, 32, 32],\n",
       "         [ 1, 33,  2, 23,  0, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32],\n",
       "         [ 1, 33,  4, 26,  0, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32],\n",
       "         [ 1, 33,  6,  2,  3,  5,  9,  4,  8,  0, 32, 32, 32, 32, 32],\n",
       "         [ 1, 33, 12,  3,  8,  0, 32, 32, 32, 32, 32, 32, 32, 32, 32],\n",
       "         [ 1, 25,  0, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32],\n",
       "         [ 1,  2, 33, 18,  2, 13,  5,  2, 10,  0, 32, 32, 32, 32, 32],\n",
       "         [ 1,  5,  4,  0, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32],\n",
       "         [ 1, 13,  6,  2,  3,  5,  2,  0, 32, 32, 32, 32, 32, 32, 32],\n",
       "         [ 1, 33, 25, 33, 22, 25, 22, 22, 22,  0, 32, 32, 32, 32, 32],\n",
       "         [ 1,  8,  2, 23,  0, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32],\n",
       "         [ 1, 33,  4, 26,  7,  0, 32, 32, 32, 32, 32, 32, 32, 32, 32],\n",
       "         [ 1, 20,  0, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32],\n",
       "         [ 0, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32]]),\n",
       " tensor([ 1,  3, 10,  0,  0,  4,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  2]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(data):\n",
    "    data.sort(key=lambda x: len(x[0]), reverse=True)\n",
    "    sentences, words, tags = zip(*data)\n",
    "\n",
    "    # Merge questions (from tuple of 1D tensor to 2D tensor).\n",
    "    sent_lengths = [len(sent) for sent in sentences]\n",
    "    inputs = torch.zeros(len(sentences), max(sent_lengths)).long()\n",
    "    labels = torch.zeros(len(sentences), max(sent_lengths)).long()\n",
    "    chars = torch.zeros(len(sentences), max(sent_lengths), MAX_WORD_LEN).long()\n",
    "    for i, (sent, lab, ch) in enumerate(zip(sentences, tags, words)):\n",
    "        end = sent_lengths[i]\n",
    "        inputs[i, :end] = sent[:end]\n",
    "        labels[i, :end] = lab[:end]\n",
    "        chars[i, :end] = ch[:end]\n",
    "    return inputs, chars, labels, sent_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader = data.DataLoader(train_dataset, BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "valid_data_loader = data.DataLoader(valid_dataset, BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "test_data_loader = data.DataLoader(test_dataset, BATCH_SIZE, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = next(iter(train_data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 41]), torch.Size([64, 41, 15]), torch.Size([64, 41]), 64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[0].shape, sample[1].shape, sample[2].shape, len(sample[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharBiLSTMCRF(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim, hid_dim, char_emb_dim, char_hid_dim, char_vocab_size, tag_vocab_size, sent_pad_token, tag_start_token, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.hid_dim = hid_dim\n",
    "        self.sent_pad_token = sent_pad_token\n",
    "        self.tag_start_token = tag_start_token\n",
    "        self.tag_vocab_size = tag_vocab_size\n",
    "\n",
    "        self.char_embedding = nn.Embedding(char_vocab_size, char_emb_dim, padding_idx=0)\n",
    "        self.char_lstm = nn.LSTM(char_emb_dim, char_hid_dim, bidirectional=True, batch_first=True)\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(\n",
    "            emb_dim + char_hid_dim,\n",
    "            hid_dim,\n",
    "            bidirectional=True,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.emission = nn.Linear(hid_dim * 2, tag_vocab_size)\n",
    "        self.transition = nn.Parameter(torch.rand(tag_vocab_size, tag_vocab_size))\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, sentences, lengths, words, tags):\n",
    "        # sentences => [batch_size, seq_len]\n",
    "        # lengths => [batch_size]\n",
    "        # words => [batch_size, seq_len, word_len]\n",
    "        # tags => [batch_size, seq_len]\n",
    "\n",
    "        char_final_hidden = []\n",
    "        for word in words:\n",
    "            # word => [seq_len, word_len]\n",
    "            char_embed = self.char_embedding(word)\n",
    "            char_embed = self.dropout(char_embed)\n",
    "            # char_embed => [seq_len, word_len, char_emb_dim]\n",
    "\n",
    "            _, (char_hidden, _) = self.char_lstm(char_embed)\n",
    "            # char_hidden => [2, seq_len, char_hid_dim]\n",
    "\n",
    "            # add the final forward and backward hidden states\n",
    "            char_combined = char_hidden[-1, :, :] + char_hidden[-2, :, :]\n",
    "            # char_combined => [seq_len, char_hid_dim]\n",
    "\n",
    "            char_final_hidden.append(char_combined)\n",
    "        \n",
    "        char_encoding = torch.stack(char_final_hidden)\n",
    "        # char_encoding => [batch_size, seq_len, char_hid_dim]\n",
    "\n",
    "        mask = (sentences != self.sent_pad_token).to(device)\n",
    "        # mask => [batch_size, seq_len]\n",
    "\n",
    "        embed = self.embedding(sentences)\n",
    "        embed = self.dropout(embed)\n",
    "        # embed => [batch_size, seq_len, emb_dim]\n",
    "\n",
    "        embed_with_char = torch.cat((embed, char_encoding), dim=-1)\n",
    "        # embed_with_char => [batch_size, seq_len, emb_dim + char_hid_dim]\n",
    "\n",
    "        packed_input = nn.utils.rnn.pack_padded_sequence(embed_with_char, lengths, batch_first=True)\n",
    "        packed_output, _ = self.lstm(packed_input)\n",
    "        outputs, _ = nn.utils.rnn.pad_packed_sequence(packed_output, batch_first=True)\n",
    "        # outputs => [batch_size, seq_len, hid_dim * 2]\n",
    "\n",
    "        combined = torch.cat((outputs[:, :, :self.hid_dim], outputs[:, :, self.hid_dim:]), dim=-1)\n",
    "        combined = self.dropout(combined)\n",
    "        # combined => [batch_size, seq_len, hid_dim * 2]\n",
    "\n",
    "        emission_scores = self.emission(combined)\n",
    "        # emission_scores => [batch_size, seq_len, tag_size]\n",
    "\n",
    "        loss = self.vitebri_loss(tags, mask, emission_scores)\n",
    "        # loss => [batch_size]\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def vitebri_loss(self, tags, mask, emit_scores):\n",
    "        # tags => [batch_size, seq_len]\n",
    "        # mask => [batch_size, seq_len]\n",
    "        # emit_scores => [batch_size, seq_len, tag_size]\n",
    "\n",
    "        batch_size, sent_len = tags.shape\n",
    "\n",
    "        # calculate the ground truth score\n",
    "        score = torch.gather(emit_scores, 2, tags.unsqueeze(2)).squeeze(2)\n",
    "        # emission scores of actual tags\n",
    "        # score => [batch_size, seq_len]\n",
    "\n",
    "        # add the transition scores to the emission scores\n",
    "        # ignore the start token tag score\n",
    "        score[:, 1:] += self.transition[tags[:, :-1], tags[:, 1:]]\n",
    "\n",
    "        # consider only the scores of actual tokens not the padded\n",
    "        gold_scores = (score * mask.type(torch.float)).sum(dim=1)\n",
    "        # gold_scores => [batch_size]\n",
    "\n",
    "        # calculate the scores of the partition (Z)\n",
    "        # tensor to hold the accumulated sequence scores at each time step\n",
    "        # at the inital time step score will be on dim=0\n",
    "        scores_upto_t = emit_scores[:, 0].unsqueeze(1)\n",
    "        # scores_upto_t => [batch_size, 1, tag_size]\n",
    "\n",
    "        for i in range(1, sent_len):\n",
    "            # get the current batch_size\n",
    "            batch_t = mask[:, i].sum()\n",
    "\n",
    "            # get the accumulated scores till now (only the current batch size)\n",
    "            scores_unpad = scores_upto_t[:batch_t]\n",
    "            # scores_unpad => [batch_t, 1, tag_size]\n",
    "\n",
    "            # add the transition scores for this time step\n",
    "            scores_with_trans = emit_scores[:batch_t, i].unsqueeze(1) + self.transition\n",
    "            # scores_with_trans => [batch_t, tag_size, tag_size]\n",
    "\n",
    "            # add to the accumulation\n",
    "            sum_scores = scores_unpad.transpose(1, 2) + scores_with_trans\n",
    "            # sum_scores => [batch_t, tag_size, tag_size]\n",
    "            \n",
    "            # apply the following to overcome the overflow problems\n",
    "            # since the exp(some_big_number) will cause issues \n",
    "            # log(Σ exp(z_k)) = max(z) + log(Σ exp(z_k - max(z)))\n",
    "            # log(Σ exp(z_k)) = log(Σ exp(z_k - c + c))\n",
    "            #                 = log(Σ exp(z_k - c) * exp(c))\n",
    "            #                 = log(Σ exp(z_k - c)) + log(exp(c))\n",
    "            #                 = log(Σ exp(z_k - c)) + c\n",
    "            # by taking c as max(z)\n",
    "            # log(Σ exp(z_k)) = max(z) + log(Σ exp(z_k - max(z))) [log_sum_exp]\n",
    "            # get the maximum score of the current time step\n",
    "            max_t = sum_scores.max(dim=1)[0].unsqueeze(1)\n",
    "            # max_t => [batch_t, 1, tag_size]\n",
    "\n",
    "            sum_scores = sum_scores - max_t\n",
    "            # sum_scores => [batch_t, tag_size, tag_size]\n",
    "\n",
    "            scores_t = max_t + torch.logsumexp(sum_scores, dim=1).unsqueeze(1)\n",
    "            # scores_t => [batch_t, 1, tag_size]\n",
    "\n",
    "            # update the accumulation scores\n",
    "            scores_upto_t = torch.cat((scores_t, scores_upto_t[batch_t:]), dim=0)\n",
    "            # scores_upto_t => [batch_size, 1, tag_size]\n",
    "        \n",
    "        final_scores = scores_upto_t.squeeze(1)\n",
    "        # final_scores => [batch_size, tag_size]\n",
    "\n",
    "        max_final_scores = final_scores.max(dim=-1)[0]\n",
    "        # max_final_scores => [batch_size]\n",
    "\n",
    "        predicted_scores = max_final_scores + torch.logsumexp(final_scores - max_final_scores.unsqueeze(1), dim=1)\n",
    "        # predicted_scores => [batch_size]\n",
    "\n",
    "        vitebri_loss = predicted_scores - gold_scores\n",
    "        # vitebri_loss => [batch_size]\n",
    "\n",
    "        return vitebri_loss\n",
    "    \n",
    "    def predict(self, sentences, lengths, words):\n",
    "        # sentences => [batch_size, seq_len]\n",
    "        # lengths => [batch_size]\n",
    "        # words => [batch_size, seq_len, word_len]\n",
    "\n",
    "        batch_size = sentences.size(0)\n",
    "\n",
    "        char_final_hidden = []\n",
    "        for word in words:\n",
    "            # word => [seq_len, word_len]\n",
    "            char_embed = self.char_embedding(word)\n",
    "            char_embed = self.dropout(char_embed)\n",
    "            # char_embed => [seq_len, word_len, char_emb_dim]\n",
    "\n",
    "            _, (char_hidden, _) = self.char_lstm(char_embed)\n",
    "            # char_hidden => [2, seq_len, char_hid_dim]\n",
    "\n",
    "            # add the final forward and backward hidden states\n",
    "            char_combined = char_hidden[-1, :, :] + char_hidden[-2, :, :]\n",
    "            # char_combined => [seq_len, char_hid_dim]\n",
    "\n",
    "            char_final_hidden.append(char_combined)\n",
    "        \n",
    "        char_encoding = torch.stack(char_final_hidden)\n",
    "        # char_encoding => [batch_size, seq_len, char_hid_dim]\n",
    "\n",
    "        mask = (sentences != self.sent_pad_token).to(device)\n",
    "        # mask => [batch_size, seq_len]\n",
    "\n",
    "        embed = self.embedding(sentences)\n",
    "        embed = self.dropout(embed)\n",
    "        # embed => [batch_size, seq_len, emb_dim]\n",
    "\n",
    "        embed_with_char = torch.cat((embed, char_encoding), dim=-1)\n",
    "        # embed_with_char => [batch_size, seq_len, emb_dim + char_hid_dim]\n",
    "\n",
    "        packed_inp = nn.utils.rnn.pack_padded_sequence(embed_with_char, lengths, batch_first=True)\n",
    "        packed_output, _ = self.lstm(packed_inp)\n",
    "        outputs, _ = nn.utils.rnn.pad_packed_sequence(packed_output, batch_first=True)\n",
    "        # outputs => [batch_size, seq_len, hid_dim * 2]\n",
    "\n",
    "        combined = torch.cat((outputs[:, :, :self.hid_dim], outputs[:, :, self.hid_dim:]), dim=-1)\n",
    "        combined = self.dropout(combined)\n",
    "        # combined => [batch_size, seq_len, hid_dim * 2]\n",
    "\n",
    "        emission_scores = self.emission(combined)\n",
    "        # emission_scores => [batch_size, seq_len, tag_size]\n",
    "\n",
    "        # to store the tags predicted at each time step\n",
    "        # since at the begining every tag is start tag create the list with start tags\n",
    "        tags = [[[self.tag_start_token] for _ in range(self.tag_vocab_size)]] * batch_size\n",
    "        # tags => [batch_size, tag_size, 1]\n",
    "\n",
    "        scores_upto_t = emission_scores[:, 0].unsqueeze(1)\n",
    "        # scores_upto_t => [batch_size, 1, tag_size]\n",
    "\n",
    "        for i in range(1, max(lengths)):\n",
    "            # get the current batch_size\n",
    "            batch_t = mask[:, i].sum()\n",
    "\n",
    "            # get the accumulated scores till now (only the current batch size)\n",
    "            scores_unpad = scores_upto_t[:batch_t]\n",
    "            # scores_unpad => [batch_t, 1, tag_size]\n",
    "\n",
    "            # add the transition scores for this time step\n",
    "            scores_with_trans = emission_scores[:batch_t, i].unsqueeze(1) + self.transition\n",
    "            # scores_with_trans => [batch_t, tag_size, tag_size]\n",
    "\n",
    "            # add to the accumulation\n",
    "            sum_scores = scores_unpad.transpose(1, 2) + scores_with_trans\n",
    "            # sum_scores => [batch_t, tag_size, tag_size]\n",
    "\n",
    "            max_scores_t, max_ids_t = torch.max(sum_scores, dim=1)\n",
    "            max_ids_t = max_ids_t.tolist()\n",
    "            # max_scores_t => [batch_t, tag_size]\n",
    "            # max_ids_t => [batch_t, tag_size]\n",
    "\n",
    "            # add the current time step predicted tags \n",
    "            tags[:batch_t] = [[tags[b][k] + [j] for j, k in enumerate(max_ids_t[b])] for b in range(batch_t)]\n",
    "            \n",
    "            # update the accumulation scores\n",
    "            scores_upto_t = torch.cat((max_scores_t.unsqueeze(1), scores_upto_t[batch_t:]), dim=0)\n",
    "            # scores_upto_t => [batch_size, tag_size]\n",
    "\n",
    "        scores = scores_upto_t.squeeze(1)\n",
    "        # scores => [batch_size, tag_size]\n",
    "\n",
    "        _, max_ids = torch.max(scores, dim=1)\n",
    "        max_ids = max_ids.tolist()\n",
    "        # max_ids => [batch_size]\n",
    "\n",
    "        # tags => [batch_size, tag_size, seq_len]\n",
    "        tags = [tags[b][k] for b, k in enumerate(max_ids)]\n",
    "        # tags => [batch_size, seq_len]\n",
    "\n",
    "        return tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CharBiLSTMCRF(\n",
       "  (char_embedding): Embedding(34, 20, padding_idx=0)\n",
       "  (char_lstm): LSTM(20, 50, batch_first=True, bidirectional=True)\n",
       "  (embedding): Embedding(9620, 50, padding_idx=0)\n",
       "  (lstm): LSTM(100, 200, batch_first=True, bidirectional=True)\n",
       "  (emission): Linear(in_features=400, out_features=20, bias=True)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(words_vocab)\n",
    "sent_pad_token = words_vocab[words_vocab.PAD]\n",
    "tag_start_token = tags_vocab[tags_vocab.START]\n",
    "emb_dim = 50\n",
    "hid_dim = 200\n",
    "char_emb_dim = 20\n",
    "char_hid_dim = 50\n",
    "char_vocab_size = len(chars_vocab)\n",
    "tag_vocab_size = len(tags_vocab)\n",
    "model = CharBiLSTMCRF(\n",
    "    vocab_size,\n",
    "    emb_dim,\n",
    "    hid_dim,\n",
    "    char_emb_dim,\n",
    "    char_hid_dim,\n",
    "    char_vocab_size,\n",
    "    tag_vocab_size,\n",
    "    sent_pad_token,\n",
    "    tag_start_token\n",
    ")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 1,002,100 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, clip):\n",
    "    model.train()\n",
    "\n",
    "    epoch_loss = 0\n",
    "    total_sentences = 0\n",
    "\n",
    "    for batch in iterator:\n",
    "        sentences = batch[0].to(device)\n",
    "        words = batch[1].to(device)\n",
    "        tags = batch[2].to(device)\n",
    "        seq_lengths = batch[3]\n",
    "        # sentences => [batch_size, seq_len]\n",
    "        # words => [batch_size, seq_len, word_len]\n",
    "        # tags => [batch_size, seq_len]\n",
    "        # seq_lengths => [batch_size]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        batch_loss = model(sentences, seq_lengths, words, tags)\n",
    "        # batch_loss => [batch_size]\n",
    "\n",
    "        loss = batch_loss.mean()\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += batch_loss.sum().item()\n",
    "        total_sentences += len(sentences)\n",
    "\n",
    "    return epoch_loss / total_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    total_sentences = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            sentences = batch[0].to(device)\n",
    "            words = batch[1].to(device)\n",
    "            tags = batch[2].to(device)\n",
    "            seq_lengths = batch[3]\n",
    "            # sentences => [batch_size, seq_len]\n",
    "            # words => [batch_size, seq_len, word_len]\n",
    "            # tags => [batch_size, seq_len]\n",
    "            # seq_lengths => [batch_size]\n",
    "\n",
    "            batch_loss = model(sentences, seq_lengths, words, tags)\n",
    "            # batch_loss => [batch_size]\n",
    "\n",
    "            loss = batch_loss.mean()\n",
    "\n",
    "            epoch_loss += batch_loss.sum().item()\n",
    "            total_sentences += len(sentences)\n",
    "        \n",
    "    return epoch_loss / total_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 13m 58s\n",
      "\tTrain Loss: 7.989 | Val. Loss: 1.731\n",
      "Epoch: 02 | Epoch Time: 13m 38s\n",
      "\tTrain Loss: 1.768 | Val. Loss: 1.542\n",
      "Epoch: 03 | Epoch Time: 13m 16s\n",
      "\tTrain Loss: 1.580 | Val. Loss: 1.482\n",
      "Epoch: 04 | Epoch Time: 13m 17s\n",
      "\tTrain Loss: 1.491 | Val. Loss: 1.495\n",
      "Epoch: 05 | Epoch Time: 13m 15s\n",
      "\tTrain Loss: 1.438 | Val. Loss: 1.443\n",
      "Epoch: 06 | Epoch Time: 13m 17s\n",
      "\tTrain Loss: 1.389 | Val. Loss: 1.488\n",
      "Epoch: 07 | Epoch Time: 13m 17s\n",
      "\tTrain Loss: 1.359 | Val. Loss: 1.486\n",
      "Epoch: 08 | Epoch Time: 13m 22s\n",
      "\tTrain Loss: 1.341 | Val. Loss: 1.439\n",
      "Epoch: 09 | Epoch Time: 13m 25s\n",
      "\tTrain Loss: 1.328 | Val. Loss: 1.508\n",
      "Epoch: 10 | Epoch Time: 13m 25s\n",
      "\tTrain Loss: 1.304 | Val. Loss: 1.505\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 10\n",
    "CLIP = 2\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss = train(model, train_data_loader, optimizer, CLIP)\n",
    "    valid_loss = evaluate(model, valid_data_loader)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'model.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Val. Loss: {valid_loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.422\n"
     ]
    }
   ],
   "source": [
    "test_loss = evaluate(model, test_data_loader)\n",
    "print(f'Test Loss: {test_loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_metrics(model, iterator):\n",
    "    model.eval()\n",
    "\n",
    "    fin_outputs = []\n",
    "    fin_targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            sentences = batch[0].to(device)\n",
    "            words = batch[1].to(device)\n",
    "            tags = batch[2].to(device)\n",
    "            seq_lengths = batch[3]\n",
    "            # sentences => [batch_size, seq_len]\n",
    "            # words => [batch_size, seq_len, word_len]\n",
    "            # tags => [batch_size, seq_len]\n",
    "            # seq_lengths => [batch_size]\n",
    "\n",
    "            predictions = model.predict(sentences, seq_lengths, words)\n",
    "            # predictions => [batch_size, seq_len]\n",
    "\n",
    "            fin_outputs.extend(predictions)\n",
    "            fin_targets.extend(tags.detach().cpu().numpy().tolist())\n",
    "        \n",
    "    assert len(fin_outputs) == len(fin_targets)\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    trans_trg = mlb.fit_transform(fin_targets)\n",
    "    trans_pred = mlb.transform(fin_outputs)\n",
    "\n",
    "    cf = metrics.classification_report(trans_trg, trans_pred)\n",
    "    print(cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      4796\n",
      "           1       1.00      1.00      1.00      4796\n",
      "           2       1.00      1.00      1.00      4796\n",
      "           3       0.92      0.96      0.94      2496\n",
      "           4       0.97      0.95      0.96      1688\n",
      "           5       0.90      0.78      0.84      1623\n",
      "           6       0.90      0.96      0.93      1071\n",
      "           7       0.91      0.91      0.91      1361\n",
      "           8       0.87      0.80      0.84       879\n",
      "           9       0.98      0.94      0.96      1303\n",
      "          10       0.81      0.88      0.84       595\n",
      "          11       0.87      0.80      0.84       395\n",
      "          12       0.33      0.02      0.04        42\n",
      "          13       0.87      0.42      0.57        31\n",
      "          14       0.00      0.00      0.00        25\n",
      "          15       0.67      0.25      0.36        16\n",
      "          16       1.00      0.73      0.85        15\n",
      "          17       0.86      0.50      0.63        12\n",
      "          18       1.00      0.50      0.67         4\n",
      "\n",
      "   micro avg       0.96      0.95      0.96     25944\n",
      "   macro avg       0.83      0.71      0.75     25944\n",
      "weighted avg       0.96      0.95      0.96     25944\n",
      " samples avg       0.97      0.96      0.96     25944\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/patsnap/anaconda2/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "cal_metrics(model, test_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(sentence):\n",
    "    if isinstance(sentence, str):\n",
    "        tokens = [words_vocab[words_vocab.START]] + sentence.split() + [words_vocab[words_vocab.END]]\n",
    "    else:\n",
    "        tokens = sentence\n",
    "    \n",
    "    chars = [['<START']] + [['<START>'] + [ch for ch in word] + ['<END>'] for word in tokens[1:-1]] + [['<END>']]\n",
    "\n",
    "    char_seq = []\n",
    "    for word in chars:\n",
    "        word_len = len(word)\n",
    "        # truncate the word if it is greater than max_word_len\n",
    "        if word_len > MAX_WORD_LEN:\n",
    "            word = word[:MAX_WORD_LEN]\n",
    "        # pad the word if it less\n",
    "        else:\n",
    "            pad_length = MAX_WORD_LEN - word_len\n",
    "            word = word + [chars_vocab.PAD] * pad_length\n",
    "        \n",
    "        # convert the chars into numerical format\n",
    "        char_ids = []\n",
    "        for each_char in word: \n",
    "            char_ids.append(chars_vocab[each_char])\n",
    "        char_seq.append(char_ids)\n",
    "\n",
    "    # numericalize\n",
    "    token_ids = [words_vocab[tok] for tok in tokens]\n",
    "    \n",
    "    # seq length\n",
    "    sent_length = [len(token_ids)]\n",
    "\n",
    "    # create tensors\n",
    "    sent_tensor = torch.LongTensor(token_ids).to(device)\n",
    "    sent_tensor = sent_tensor.unsqueeze(0)\n",
    "    # sent_tensor => [1, seq_len]\n",
    "\n",
    "    char_tensor = torch.LongTensor(char_seq).to(device)\n",
    "    char_tensor = char_tensor.unsqueeze(0)\n",
    "    # char_tensor => [1, seq_len, word_len]\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        predictions = model.predict(sent_tensor, sent_length, char_tensor)\n",
    "    \n",
    "    predictions = predictions[0]\n",
    "    predicted_tags = []\n",
    "    for i in predictions:\n",
    "        predicted_tags.append(tags_vocab.id2word(i))\n",
    "    \n",
    "    return tokens, predicted_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred. Tag\tActual Tag\tCorrect?\tToken\n",
      "\n",
      "<START>\t\t<START>\t\t✔\t\t<START>\n",
      "O\t\tO\t\t✔\t\tThe\n",
      "O\t\tO\t\t✔\t\toffice\n",
      "O\t\tO\t\t✔\t\tof\n",
      "O\t\tO\t\t✔\t\tthe\n",
      "B-gpe\t\tB-gpe\t\t✔\t\tIsraeli\n",
      "O\t\tO\t\t✔\t\tprime\n",
      "O\t\tO\t\t✔\t\tminister\n",
      "O\t\tO\t\t✔\t\tsays\n",
      "O\t\tO\t\t✔\t\ta\n",
      "O\t\tO\t\t✔\t\tvisit\n",
      "O\t\tO\t\t✔\t\tto\n",
      "B-geo\t\tB-geo\t\t✔\t\tIsrael\n",
      "O\t\tO\t\t✔\t\tby\n",
      "O\t\tO\t\t✔\t\tthe\n",
      "O\t\tO\t\t✔\t\tforeign\n",
      "O\t\tO\t\t✔\t\tministers\n",
      "O\t\tO\t\t✔\t\tof\n",
      "B-geo\t\tB-gpe\t\t✘\t\tEgypt\n",
      "O\t\tO\t\t✔\t\tand\n",
      "B-gpe\t\tB-gpe\t\t✔\t\tJordan\n",
      "O\t\tO\t\t✔\t\twill\n",
      "O\t\tO\t\t✔\t\ttake\n",
      "O\t\tO\t\t✔\t\tplace\n",
      "B-tim\t\tB-tim\t\t✔\t\tJuly\n",
      "I-tim\t\tI-tim\t\t✔\t\t25\n",
      "O\t\tO\t\t✔\t\t,\n",
      "O\t\tO\t\t✔\t\tnot\n",
      "O\t\tO\t\t✔\t\tthis\n",
      "O\t\tO\t\t✔\t\tweek\n",
      "O\t\tO\t\t✔\t\tas\n",
      "O\t\tO\t\t✔\t\tpreviously\n",
      "O\t\tO\t\t✔\t\tplanned\n",
      "O\t\tO\t\t✔\t\t.\n",
      "<END>\t\t<END>\t\t✔\t\t<END>\n"
     ]
    }
   ],
   "source": [
    "sentence = test_sentences[0]\n",
    "actual_tags = test_tags[0]\n",
    "tokens, predicted_tag_ids = inference(sentence)\n",
    "\n",
    "print(\"Pred. Tag\\tActual Tag\\tCorrect?\\tToken\\n\")\n",
    "for token, pred_tag, actual_tag in zip(tokens, predicted_tag_ids, actual_tags):\n",
    "    correct = '✔' if pred_tag == actual_tag else '✘'\n",
    "    print(f\"{pred_tag}\\t\\t{actual_tag}\\t\\t{correct}\\t\\t{token}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred. Tag\tActual Tag\tCorrect?\tToken\n",
      "\n",
      "<START>\t\t<START>\t\t✔\t\t<START>\n",
      "O\t\tO\t\t✔\t\tAn\n",
      "B-gpe\t\tB-gpe\t\t✔\t\tIraqi\n",
      "O\t\tO\t\t✔\t\tmilitant\n",
      "O\t\tO\t\t✔\t\tgroup\n",
      "O\t\tO\t\t✔\t\t(\n",
      "O\t\tO\t\t✔\t\tthe\n",
      "B-org\t\tB-org\t\t✔\t\tIslamic\n",
      "I-org\t\tI-org\t\t✔\t\tArmy\n",
      "O\t\tO\t\t✔\t\tof\n",
      "B-geo\t\tB-geo\t\t✔\t\tIraq\n",
      "O\t\tO\t\t✔\t\t)\n",
      "O\t\tO\t\t✔\t\tposted\n",
      "O\t\tO\t\t✔\t\ta\n",
      "O\t\tO\t\t✔\t\tvideo\n",
      "O\t\tO\t\t✔\t\ton\n",
      "O\t\tO\t\t✔\t\tthe\n",
      "O\t\tO\t\t✔\t\tInternet\n",
      "B-tim\t\tB-tim\t\t✔\t\ttoday\n",
      "O\t\tO\t\t✔\t\tthat\n",
      "O\t\tO\t\t✔\t\tshowed\n",
      "O\t\tO\t\t✔\t\ta\n",
      "O\t\tO\t\t✔\t\tblindfolded\n",
      "O\t\tO\t\t✔\t\tman\n",
      "O\t\tO\t\t✔\t\tbeing\n",
      "O\t\tO\t\t✔\t\tshot\n",
      "O\t\tO\t\t✔\t\tin\n",
      "O\t\tO\t\t✔\t\tthe\n",
      "O\t\tO\t\t✔\t\tback\n",
      "O\t\tO\t\t✔\t\tof\n",
      "O\t\tO\t\t✔\t\tthe\n",
      "O\t\tO\t\t✔\t\thead\n",
      "O\t\tO\t\t✔\t\t.\n",
      "<END>\t\t<END>\t\t✔\t\t<END>\n"
     ]
    }
   ],
   "source": [
    "sentence = test_sentences[10]\n",
    "actual_tags = test_tags[10]\n",
    "tokens, predicted_tag_ids = inference(sentence)\n",
    "\n",
    "print(\"Pred. Tag\\tActual Tag\\tCorrect?\\tToken\\n\")\n",
    "for token, pred_tag, actual_tag in zip(tokens, predicted_tag_ids, actual_tags):\n",
    "    correct = '✔' if pred_tag == actual_tag else '✘'\n",
    "    print(f\"{pred_tag}\\t\\t{actual_tag}\\t\\t{correct}\\t\\t{token}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred. Tag\tToken\n",
      "\n",
      "O\t\tI\n",
      "O\t\tlike\n",
      "O\t\tto\n",
      "O\t\tlive\n",
      "O\t\tin\n",
      "B-geo\t\tNew\n",
      "I-geo\t\tYork\n"
     ]
    }
   ],
   "source": [
    "sentence = \"I like to live in New York\"\n",
    "tokens, predicted_tag_ids = inference(sentence)\n",
    "\n",
    "print(\"Pred. Tag\\tToken\\n\")\n",
    "for token, pred_tag in zip(tokens[1:-1], predicted_tag_ids[1:-1]):\n",
    "    print(f\"{pred_tag}\\t\\t{token}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred. Tag\tToken\n",
      "\n",
      "O\t\tMy\n",
      "O\t\tdream\n",
      "O\t\tis\n",
      "O\t\tto\n",
      "O\t\twork\n",
      "O\t\tat\n",
      "B-org\t\tGoogle\n"
     ]
    }
   ],
   "source": [
    "sentence = \"My dream is to work at Google\"\n",
    "tokens, predicted_tag_ids = inference(sentence)\n",
    "\n",
    "print(\"Pred. Tag\\tToken\\n\")\n",
    "for token, pred_tag in zip(tokens[1:-1], predicted_tag_ids[1:-1]):\n",
    "    print(f\"{pred_tag}\\t\\t{token}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
