{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/patsnap/anaconda2/lib/python3.7/site-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import math\n",
    "import random\n",
    "import spacy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "\n",
    "from itertools import chain\n",
    "from collections import Counter\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fdb2f2430b0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEED = 42\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile = '/Users/patsnap/Desktop/Neo4J_and_other_codes/1014-4361-bundle-archive/ner_dataset.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(datafile, encoding=\"latin1\", error_bad_lines=False)\n",
    "df = df.fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Sentence #           Word  POS Tag\n",
       "0  Sentence: 1      Thousands  NNS   O\n",
       "1  Sentence: 1             of   IN   O\n",
       "2  Sentence: 1  demonstrators  NNS   O\n",
       "3  Sentence: 1           have  VBP   O\n",
       "4  Sentence: 1        marched  VBN   O"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O',\n",
       " 'B-geo',\n",
       " 'B-gpe',\n",
       " 'B-per',\n",
       " 'I-geo',\n",
       " 'B-org',\n",
       " 'I-org',\n",
       " 'B-tim',\n",
       " 'B-art',\n",
       " 'I-art',\n",
       " 'I-per',\n",
       " 'I-gpe',\n",
       " 'I-tim',\n",
       " 'B-nat',\n",
       " 'B-eve',\n",
       " 'I-eve',\n",
       " 'I-nat']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = list(df.Tag.unique())\n",
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fdb31968b10>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "sns.countplot(df.Tag.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tags = len(tags)\n",
    "num_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_func = lambda s: [(w, t) for w, p, t in zip(s[\"Word\"].values.tolist(), s[\"POS\"].values.tolist(), s[\"Tag\"].values.tolist())]\n",
    "group = df.groupby(\"Sentence #\").apply(agg_func)\n",
    "lines = [s for s in group]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Thousands', 'O'),\n",
       " ('of', 'O'),\n",
       " ('demonstrators', 'O'),\n",
       " ('have', 'O'),\n",
       " ('marched', 'O'),\n",
       " ('through', 'O'),\n",
       " ('London', 'B-geo'),\n",
       " ('to', 'O'),\n",
       " ('protest', 'O'),\n",
       " ('the', 'O'),\n",
       " ('war', 'O'),\n",
       " ('in', 'O'),\n",
       " ('Iraq', 'B-geo'),\n",
       " ('and', 'O'),\n",
       " ('demand', 'O'),\n",
       " ('the', 'O'),\n",
       " ('withdrawal', 'O'),\n",
       " ('of', 'O'),\n",
       " ('British', 'B-gpe'),\n",
       " ('troops', 'O'),\n",
       " ('from', 'O'),\n",
       " ('that', 'O'),\n",
       " ('country', 'O'),\n",
       " ('.', 'O')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [['<START>'] + [tokens[0] for tokens in line] + ['<END'] for line in lines]\n",
    "tags = [['<START>'] + [tokens[1] for tokens in line] + ['<END'] for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47959, 47959)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences), len(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fdb26f6cfd0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sen_lengths = [len(sent) for sent in sentences]\n",
    "plt.figure(figsize=(15, 5))\n",
    "sns.countplot(sen_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38367, 4796, 4796)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences, valid_sentences, train_tags, valid_tags = train_test_split(sentences, tags, test_size=0.2, random_state=42)\n",
    "valid_sentences, test_sentences, valid_tags, test_tags = train_test_split(valid_sentences, valid_tags, test_size=0.5, random_state=42)\n",
    "len(train_sentences), len(valid_sentences), len(test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocab:\n",
    "    def __init__(self, word2id, id2word):\n",
    "        self.UNK = '<UNK>'\n",
    "        self.PAD = '<PAD>'\n",
    "        self.START = '<START>'\n",
    "        self.END = '<END>'\n",
    "        self.__word2id = word2id\n",
    "        self.__id2word = id2word\n",
    "\n",
    "    def get_word2id(self):\n",
    "        return self.__word2id\n",
    "\n",
    "    def get_id2word(self):\n",
    "        return self.__id2word\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        if self.UNK in self.__word2id:\n",
    "            return self.__word2id.get(item, self.__word2id[self.UNK])\n",
    "        return self.__word2id[item]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.__word2id)\n",
    "\n",
    "    def id2word(self, idx):\n",
    "        return self.__id2word[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(data, freq_cutoff=5, is_tags=False):\n",
    "    word_counts = Counter(chain(*data))\n",
    "    valid_words = [w for w, d in word_counts.items() if d >= freq_cutoff]\n",
    "    valid_words = sorted(valid_words, key=lambda x: word_counts[x], reverse=True)\n",
    "    valid_words += ['<PAD>']\n",
    "    word2id = {w: idx for idx, w in enumerate(valid_words)}\n",
    "    if not is_tags:\n",
    "        word2id['<UNK>'] = len(word2id)\n",
    "        valid_words += ['<UNK>']\n",
    "    return Vocab(word2id=word2id, id2word=valid_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20,\n",
       " ['O',\n",
       "  '<START>',\n",
       "  '<END',\n",
       "  'B-geo',\n",
       "  'B-tim',\n",
       "  'B-org',\n",
       "  'I-per',\n",
       "  'B-per',\n",
       "  'I-org',\n",
       "  'B-gpe',\n",
       "  'I-geo',\n",
       "  'I-tim',\n",
       "  'B-art',\n",
       "  'B-eve',\n",
       "  'I-art',\n",
       "  'I-eve',\n",
       "  'I-gpe',\n",
       "  'B-nat',\n",
       "  'I-nat',\n",
       "  '<PAD>'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_vocab = build_vocab(train_sentences)\n",
    "tags_vocab = build_vocab(train_tags, is_tags=True)\n",
    "len(tags_vocab), tags_vocab.get_id2word()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEN_LEN = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NERDataset(data.Dataset):\n",
    "    def __init__(self, sentences, tags, max_len):\n",
    "        self.sentences = sentences\n",
    "        self.tags = tags\n",
    "        self.max_len = max_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        sentence = self.sentences[item]\n",
    "        tag = self.tags[item]\n",
    "        tokens, tags = [], []\n",
    "\n",
    "        for word, t in zip(sentence, tag):\n",
    "            tokens.append(words_vocab[word])\n",
    "            tags.append(tags_vocab[t])\n",
    "\n",
    "        return torch.LongTensor(tokens), torch.LongTensor(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = NERDataset(train_sentences, train_tags, MAX_SEN_LEN)\n",
    "valid_dataset = NERDataset(valid_sentences, valid_tags, MAX_SEN_LEN)\n",
    "test_dataset = NERDataset(test_sentences, test_tags, MAX_SEN_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([   1,  150,  235,   11,   36,   72,   49, 3318,    8, 1977, 4171,  166,\n",
       "         9619, 9619, 7832,    4,  199,    7, 1385, 9619,   67, 1103,    3,    2]),\n",
       " tensor([ 1,  3, 10,  0,  0,  4,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  2]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(data):\n",
    "    data.sort(key=lambda x: len(x[0]), reverse=True)\n",
    "    sentences, tags = zip(*data)\n",
    "\n",
    "    # Merge questions (from tuple of 1D tensor to 2D tensor).\n",
    "    sent_lengths = [len(sent) for sent in sentences]\n",
    "    inputs = torch.zeros(len(sentences), max(sent_lengths)).long()\n",
    "    labels = torch.zeros(len(sentences), max(sent_lengths)).long()\n",
    "    \n",
    "    for i, (sent, lab) in enumerate(zip(sentences, tags)):\n",
    "        end = sent_lengths[i]\n",
    "        inputs[i, :end] = sent[:end]\n",
    "        labels[i, :end] = lab[:end]\n",
    "\n",
    "    return inputs, labels, sent_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader = data.DataLoader(train_dataset, BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "valid_data_loader = data.DataLoader(valid_dataset, BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "test_data_loader = data.DataLoader(test_dataset, BATCH_SIZE, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([128, 52]), torch.Size([128, 52]), 128)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = next(iter(train_data_loader))\n",
    "sample[0].shape, sample[1].shape, len(sample[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=512):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_dim, d_model, nhead, nhid, nlayers, output_dim, dropout=0.5, src_pad_idx=0):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.src_pad_idx = src_pad_idx\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
    "        encoder_layers = TransformerEncoderLayer(d_model, nhead, nhid, dropout)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
    "        self.word_encoder = nn.Embedding(input_dim, d_model)\n",
    "        self.d_model = d_model\n",
    "        self.decoder = nn.Linear(d_model, output_dim)\n",
    "\n",
    "    def _generate_src_pad_mask(self, src):\n",
    "        mask = (src == self.src_pad_idx)\n",
    "        return mask.transpose(0, 1)\n",
    "    \n",
    "    def forward(self, src):\n",
    "        # src => [src_len, batch_size]\n",
    "        \n",
    "        device = src.device\n",
    "        src_pad_mask = self._generate_src_pad_mask(src).to(device)\n",
    "        # src_pad_mask => [batch_size, src_len]\n",
    "\n",
    "        src = self.word_encoder(src) * math.sqrt(self.d_model)\n",
    "        src = self.pos_encoder(src)\n",
    "        output = self.transformer_encoder(src, src_key_padding_mask=src_pad_mask)\n",
    "        output = self.decoder(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(words_vocab)\n",
    "D_MODEL = 128\n",
    "N_HID = 256\n",
    "OUTPUT_DIM = len(tags_vocab)\n",
    "N_LAYERS = 3\n",
    "N_HEAD = 8\n",
    "DROPOUT = 0.5\n",
    "PAD_IDX = words_vocab[words_vocab.PAD]\n",
    "\n",
    "model = TransformerModel(INPUT_DIM, D_MODEL, N_HEAD, N_HID, N_LAYERS, OUTPUT_DIM, DROPOUT, PAD_IDX)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerModel(\n",
       "  (pos_encoder): PositionalEncoding(\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (transformer_encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=128, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "        (linear2): Linear(in_features=256, out_features=128, bias=True)\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.5, inplace=False)\n",
       "        (dropout2): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "      (1): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=128, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "        (linear2): Linear(in_features=256, out_features=128, bias=True)\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.5, inplace=False)\n",
       "        (dropout2): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "      (2): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=128, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.5, inplace=False)\n",
       "        (linear2): Linear(in_features=256, out_features=128, bias=True)\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.5, inplace=False)\n",
       "        (dropout2): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (word_encoder): Embedding(9620, 128)\n",
       "  (decoder): Linear(in_features=128, out_features=20, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.normal_(param.data, mean = 0, std = 0.1)\n",
    "\n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 1,631,380 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "TAG_PAD_IDX = tags_vocab[tags_vocab.PAD]\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=TAG_PAD_IDX).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_accuracy(preds, y, tag_pad_idx):\n",
    "    max_preds = preds.argmax(dim = 1, keepdim = True)\n",
    "    non_pad_elements = (y != tag_pad_idx).nonzero()\n",
    "    correct = max_preds[non_pad_elements].squeeze(1).eq(y[non_pad_elements])\n",
    "    return correct.sum() / torch.FloatTensor([y[non_pad_elements].shape[0]]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, criterion, optimizer, tag_pad_idx, clip):\n",
    "    model.train()\n",
    "\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "\n",
    "    for batch in iterator:\n",
    "        text = batch[0].transpose(0, 1).to(device)\n",
    "        tags = batch[1].transpose(0, 1).to(device)\n",
    "        # text => [seq_len, batch_size]\n",
    "        # tags => [seq_len, batch_size]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        logits = model(text)\n",
    "        # logits => [seq_len, batch_size, output_dim]\n",
    "\n",
    "        logits = logits.view(-1, logits.shape[-1])\n",
    "        # logits => [seq_len * batch_size, output_dim]\n",
    "\n",
    "        tags = tags.contiguous().view(-1)\n",
    "        # tags => [seq_len * batch_size]\n",
    "\n",
    "        loss = criterion(logits, tags)\n",
    "        acc = categorical_accuracy(logits, tags, tag_pad_idx)\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "    \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion, trg_pad_idx):\n",
    "    model.eval()\n",
    "\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            text = batch[0].transpose(0, 1).to(device)\n",
    "            tags = batch[1].transpose(0, 1).to(device)\n",
    "            # text => [seq_len, batch_size]\n",
    "            # tags => [seq_len, batch_size]\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            logits = model(text)\n",
    "            # logits => [seq_len, batch_size, output_dim]\n",
    "\n",
    "            logits = logits.view(-1, logits.shape[-1])\n",
    "            # logits => [seq_len * batch_size, output_dim]\n",
    "\n",
    "            tags = tags.contiguous().view(-1)\n",
    "            # tags => [seq_len * batch_size]\n",
    "\n",
    "            loss = criterion(logits, tags)\n",
    "            acc = categorical_accuracy(logits, tags, trg_pad_idx)\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "    \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 3m 19s\n",
      "\tTrain Loss: 0.746 | Train Acc: 88.07 | Val. Loss: 0.373 | Val Acc: 88.88\n",
      "Epoch: 02 | Epoch Time: 3m 19s\n",
      "\tTrain Loss: 0.293 | Train Acc: 91.22 | Val. Loss: 0.226 | Val Acc: 92.35\n",
      "Epoch: 03 | Epoch Time: 3m 32s\n",
      "\tTrain Loss: 0.228 | Train Acc: 92.55 | Val. Loss: 0.184 | Val Acc: 94.59\n",
      "Epoch: 04 | Epoch Time: 3m 25s\n",
      "\tTrain Loss: 0.187 | Train Acc: 94.40 | Val. Loss: 0.167 | Val Acc: 94.90\n",
      "Epoch: 05 | Epoch Time: 3m 30s\n",
      "\tTrain Loss: 0.169 | Train Acc: 94.80 | Val. Loss: 0.152 | Val Acc: 95.63\n",
      "Epoch: 06 | Epoch Time: 3m 15s\n",
      "\tTrain Loss: 0.152 | Train Acc: 95.43 | Val. Loss: 0.139 | Val Acc: 96.00\n",
      "Epoch: 07 | Epoch Time: 3m 14s\n",
      "\tTrain Loss: 0.138 | Train Acc: 96.01 | Val. Loss: 0.124 | Val Acc: 96.78\n",
      "Epoch: 08 | Epoch Time: 3m 10s\n",
      "\tTrain Loss: 0.126 | Train Acc: 96.50 | Val. Loss: 0.109 | Val Acc: 97.06\n",
      "Epoch: 09 | Epoch Time: 3m 10s\n",
      "\tTrain Loss: 0.116 | Train Acc: 96.82 | Val. Loss: 0.104 | Val Acc: 97.17\n",
      "Epoch: 10 | Epoch Time: 3m 12s\n",
      "\tTrain Loss: 0.107 | Train Acc: 97.05 | Val. Loss: 0.098 | Val Acc: 97.30\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 10\n",
    "CLIP = 2\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train(model, train_data_loader, criterion, optimizer, TAG_PAD_IDX, CLIP)\n",
    "    valid_loss, val_acc = evaluate(model, valid_data_loader, criterion, TAG_PAD_IDX)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'model.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f} | Val. Loss: {valid_loss:.3f} | Val Acc: {val_acc * 100:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.100 | Test Acc: 97.23\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = evaluate(model, test_data_loader, criterion, TAG_PAD_IDX)\n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc * 100:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_metrics(model, iterator):\n",
    "    model.eval()\n",
    "\n",
    "    fin_outputs = []\n",
    "    fin_targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            sentences = batch[0].transpose(0, 1).to(device)\n",
    "            tags = batch[1].transpose(0, 1).to(device)\n",
    "\n",
    "\n",
    "            predictions = model(sentences)\n",
    "            # predictions => [seq_len, batch_size, output_dim]\n",
    "            _, predictions = torch.max(predictions, dim=2)\n",
    "\n",
    "            fin_outputs.extend(predictions.detach().cpu().numpy().tolist())\n",
    "            fin_targets.extend(tags.detach().cpu().numpy().tolist())\n",
    "        \n",
    "    assert len(fin_outputs) == len(fin_targets)\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    trans_trg = mlb.fit_transform(fin_targets)\n",
    "    trans_pred = mlb.transform(fin_outputs)\n",
    "\n",
    "    cf = metrics.classification_report(trans_trg, trans_pred)\n",
    "    print(cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1835\n",
      "           1       1.00      1.00      1.00        38\n",
      "           2       1.00      1.00      1.00      1256\n",
      "           3       0.95      0.96      0.95      1157\n",
      "           4       0.96      0.88      0.92       941\n",
      "           5       0.95      0.66      0.78       835\n",
      "           6       0.77      0.93      0.84       701\n",
      "           7       0.91      0.81      0.86       676\n",
      "           8       0.80      0.80      0.80       764\n",
      "           9       0.96      0.97      0.96       728\n",
      "          10       0.89      0.61      0.72       528\n",
      "          11       0.76      0.05      0.10       470\n",
      "          12       0.00      0.00      0.00        46\n",
      "          13       0.00      0.00      0.00        34\n",
      "          14       0.00      0.00      0.00        45\n",
      "          15       0.00      0.00      0.00        24\n",
      "          16       0.00      0.00      0.00        15\n",
      "          17       0.00      0.00      0.00        13\n",
      "          18       0.00      0.00      0.00         5\n",
      "\n",
      "   micro avg       0.93      0.84      0.88     10111\n",
      "   macro avg       0.58      0.51      0.52     10111\n",
      "weighted avg       0.91      0.84      0.86     10111\n",
      " samples avg       0.94      0.87      0.90     10111\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/patsnap/anaconda2/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "cal_metrics(model, test_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
