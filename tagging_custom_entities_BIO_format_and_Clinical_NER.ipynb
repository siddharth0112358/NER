{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mapping custom tags "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plac\n",
    "from spacy.lang.en import English\n",
    "from spacy.matcher import PhraseMatcher\n",
    "from spacy.tokens import Doc, Span, Token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_drug_entities():\n",
    "    drugs = np.load(\"/Users/sdeshpande/Desktop/bioinformatices/Clinical_NER_train/drug_entities.npy\")\n",
    "    drugs = [d.lower() for d in drugs if (len(d)>4)]\n",
    "    non_ents = [\"solution\"]\n",
    "    for ent in non_ents:\n",
    "        drugs.remove(ent)\n",
    "    drugs = list(set(drugs))\n",
    "    return drugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "drugs = load_drug_entities()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ferrous sulfate',\n",
       " 'cosyntropin',\n",
       " 'cipro hc otic suspension',\n",
       " 'flovent',\n",
       " 'fluphenazine decanoate',\n",
       " 'cinacalcet',\n",
       " 'golytely',\n",
       " 'critic-aid clear',\n",
       " '*nf* praziquantel',\n",
       " 'buprenorphine-naloxone (8mg-2mg)',\n",
       " 'jolessa',\n",
       " 'propofol',\n",
       " 'phenobarbital',\n",
       " '*nf* interferon beta-1a',\n",
       " 'insulin lispro 75/25',\n",
       " 'methylprednisolone na succ',\n",
       " 'neomycin-polymyxin-',\n",
       " '*nf* glycopyrrolate',\n",
       " 'terconazole 80mg vag. supp',\n",
       " 'maribavir 100mg or placebo (*ind*)']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drugs[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_drug_entities():\n",
    "    drugs = np.load(\"/Users/sdeshpande/Desktop/bioinformatices/Clinical_NER_train/drug_entities.npy\")\n",
    "    drugs = [d.lower() for d in drugs if (len(d)>4)]\n",
    "    non_ents = [\"solution\"]\n",
    "    for ent in non_ents:\n",
    "        drugs.remove(ent)\n",
    "    drugs = list(set(drugs))\n",
    "    return drugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dose_entities():\n",
    "    doses = np.load(\"/Users/sdeshpande/Desktop/bioinformatices/Clinical_NER_train/dose_entities.npy\")\n",
    "    doses = [d.lower() for d in doses if len(d)>1]\n",
    "    return list(set(doses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['5ml oral syr', '15 mg/5 ml oral soln', '120mg suppository', '1 mg vial', '2 g / 100 ml premix bag', '10 meq (1080 mg) tablet', '20 mg/ml oral concentrate', '100mg/10ml vial', '150-30-6-150 mg-unit-mg-mg', '1mg oral syr.']\n"
     ]
    }
   ],
   "source": [
    "dose_ents = load_dose_entities()\n",
    "print(dose_ents[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: en_core_web_md==2.3.1 from https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.3.1/en_core_web_md-2.3.1.tar.gz#egg=en_core_web_md==2.3.1 in /Users/sdeshpande/opt/anaconda3/lib/python3.8/site-packages (2.3.1)\n",
      "Requirement already satisfied: spacy<2.4.0,>=2.3.0 in /Users/sdeshpande/opt/anaconda3/lib/python3.8/site-packages (from en_core_web_md==2.3.1) (2.3.2)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /Users/sdeshpande/opt/anaconda3/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (1.0.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/sdeshpande/opt/anaconda3/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (3.0.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/sdeshpande/opt/anaconda3/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (1.0.2)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /Users/sdeshpande/opt/anaconda3/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (0.8.0)\n",
      "Requirement already satisfied: setuptools in /Users/sdeshpande/opt/anaconda3/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (49.2.0.post20200714)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/sdeshpande/opt/anaconda3/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (4.47.0)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /Users/sdeshpande/opt/anaconda3/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (1.1.3)\n",
      "Requirement already satisfied: thinc==7.4.1 in /Users/sdeshpande/opt/anaconda3/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (7.4.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/sdeshpande/opt/anaconda3/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (2.0.3)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/sdeshpande/opt/anaconda3/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (1.16.1)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /Users/sdeshpande/opt/anaconda3/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (1.0.2)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /Users/sdeshpande/opt/anaconda3/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (0.4.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/sdeshpande/opt/anaconda3/lib/python3.8/site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (2.24.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/sdeshpande/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/sdeshpande/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (1.25.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/sdeshpande/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/sdeshpande/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_md==2.3.1) (3.0.4)\n",
      "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_md')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EntityMatcher(object):\n",
    "    name = 'entity_matcher'\n",
    "\n",
    "    def __init__(self, nlp, drugs, label):\n",
    "        patterns = [nlp(text) for text in drugs]\n",
    "        self.matcher = PhraseMatcher(nlp.vocab)\n",
    "        self.matcher.add(label, None, *patterns)\n",
    "\n",
    "    def __call__(self, doc):\n",
    "        matches = self.matcher(doc)\n",
    "        seen_tokens = set()\n",
    "        new_entities = []\n",
    "        entities = doc.ents\n",
    "        for match_id, start, end in matches:\n",
    "        #    span = Span(doc, start, end, label=match_id)\n",
    "        #    doc.ents = list(doc.ents) + [span]\n",
    "            # check for end - 1 here because boundaries are inclusive\n",
    "            if start not in seen_tokens and end - 1 not in seen_tokens:\n",
    "                new_entities.append(Span(doc, start, end, label=match_id))\n",
    "                entities = [\n",
    "                    e for e in entities if not (e.start < end and e.end > start)\n",
    "                ]\n",
    "                seen_tokens.update(range(start, end))\n",
    "\n",
    "        doc.ents = tuple(entities) + tuple(new_entities)\n",
    "        return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EntityMatcherDose(object):\n",
    "    name = 'entity_matcher_dose'\n",
    "\n",
    "    def __init__(self, nlp, dose_ents, label):\n",
    "        patterns = [nlp(text) for text in dose_ents]\n",
    "        self.matcher = PhraseMatcher(nlp.vocab)\n",
    "        self.matcher.add(label, None, *patterns)\n",
    "\n",
    "    def __call__(self, doc):\n",
    "        matches = self.matcher(doc)\n",
    "        seen_tokens = set()\n",
    "        new_entities = []\n",
    "        entities = doc.ents\n",
    "        for match_id, start, end in matches:\n",
    "        #    span = Span(doc, start, end, label=match_id)\n",
    "        #    doc.ents = list(doc.ents) + [span]\n",
    "            # check for end - 1 here because boundaries are inclusive\n",
    "            if start not in seen_tokens and end - 1 not in seen_tokens:\n",
    "                new_entities.append(Span(doc, start, end, label=match_id))\n",
    "                entities = [\n",
    "                    e for e in entities if not (e.start < end and e.end > start)\n",
    "                ]\n",
    "                seen_tokens.update(range(start, end))\n",
    "\n",
    "        doc.ents = tuple(entities) + tuple(new_entities)\n",
    "        return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_matcher_3 = Matcher(nlp.vocab)\n",
    "pattern = [{\"TEXT\": {\"REGEX\": \"[0-9]+\"}}]\n",
    "entity_matcher_3.add(\"MEASUREMENTS\", None, pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EntityMatcherNumber(object):\n",
    "    name = 'entity_matcher_number'\n",
    "\n",
    "    def __init__(self, nlp, label):\n",
    "        patterns = [{\"TEXT\": {\"REGEX\": \"[0-9]+\"}}]\n",
    "        self.matcher = Matcher(nlp.vocab)\n",
    "        self.matcher.add(label, None, patterns)\n",
    "\n",
    "    def __call__(self, doc):\n",
    "        matches = self.matcher(doc)\n",
    "        seen_tokens = set()\n",
    "        new_entities = []\n",
    "        entities = doc.ents\n",
    "        for match_id, start, end in matches:\n",
    "        #    span = Span(doc, start, end, label=match_id)\n",
    "        #    doc.ents = list(doc.ents) + [span]\n",
    "            # check for end - 1 here because boundaries are inclusive\n",
    "            if start not in seen_tokens and end - 1 not in seen_tokens:\n",
    "                new_entities.append(Span(doc, start, end, label=match_id))\n",
    "                entities = [\n",
    "                    e for e in entities if not (e.start < end and e.end > start)\n",
    "                ]\n",
    "                seen_tokens.update(range(start, end))\n",
    "\n",
    "        doc.ents = tuple(entities) + tuple(new_entities)\n",
    "        return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_matcher_3 = EntityMatcherNumber(nlp, 'MEASUREMENTS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Regex pattern matching reference code for spacy\n",
    "\n",
    "# nlp = spacy.load(\"en_core_web_lg\")\n",
    "# matcher = Matcher(nlp.vocab)\n",
    "# pattern = [{\"TEXT\": {\"REGEX\": \"^[Uu](\\.?|nited)$\"}},\n",
    "#            {\"TEXT\": {\"REGEX\": \"^[Ss](\\.?|tates)$\"}}]\n",
    "# matcher.add(\"US\", None, pattern)\n",
    "# doc = nlp(u\"I'm from the United States.\")\n",
    "# matches = matcher(doc)\n",
    "# for match_id, start, end in matches:\n",
    "#     string_id = nlp.vocab.strings[match_id]\n",
    "#     span = doc[start:end]\n",
    "#     print(match_id, string_id, start, end, span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_matcher = EntityMatcher(nlp, drugs, 'DRUGS')\n",
    "entity_matcher_2 = EntityMatcherDose(nlp, dose_ents, 'DOSES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tagger', 'parser', 'ner', 'entity_matcher', 'entity_matcher_dose']\n"
     ]
    }
   ],
   "source": [
    "nlp.add_pipe(entity_matcher)\n",
    "nlp.add_pipe(entity_matcher_2)\n",
    "print(nlp.pipe_names)  # the components in the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tagger', 'parser', 'ner', 'entity_matcher', 'entity_matcher_dose', 'entity_matcher_number']\n"
     ]
    }
   ],
   "source": [
    "nlp.add_pipe(entity_matcher_3)\n",
    "print(nlp.pipe_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('guanfacine', 'DRUGS'), ('ertapenem', 'DRUGS'), ('sodium', 'DRUGS'), ('insulin', 'DRUGS'), ('isosorbide', 'DRUGS'), ('nexium', 'DRUGS'), ('aprotinin', 'DRUGS'), ('metronidazole', 'DRUGS'), ('critic-aid', 'DRUGS'), ('0.4mg/2ml', 'MEASUREMENTS'), ('0.4mg', 'MEASUREMENTS'), ('10', 'MEASUREMENTS'), ('50', 'MEASUREMENTS'), ('mg', 'DOSES'), ('capsule', 'DOSES')]\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(u\"guanfacine, capecitabine, ertapenem sodium, insulin lispro, isosorbide mononitrate , nexium, aprotinin, metronidazole (flagyl), critic-aid, 0.4mg/2ml vial, 0.4mg/hr patch (10mg), 50 mg capsule. I have a cat\")\n",
    "print([(ent.text, ent.label_) for ent in doc.ents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "guanfacine 0 10 DRUGS\n",
      "ertapenem 26 35 DRUGS\n",
      "sodium 36 42 DRUGS\n",
      "insulin 44 51 DRUGS\n",
      "isosorbide 60 70 DRUGS\n",
      "nexium 85 91 DRUGS\n",
      "aprotinin 93 102 DRUGS\n",
      "metronidazole 104 117 DRUGS\n",
      "critic-aid 128 138 DRUGS\n",
      "0.4mg/2ml 140 149 MEASUREMENTS\n",
      "0.4mg 156 161 MEASUREMENTS\n",
      "10 172 174 MEASUREMENTS\n",
      "50 179 181 MEASUREMENTS\n",
      "mg 182 184 DOSES\n",
      "capsule 185 192 DOSES\n"
     ]
    }
   ],
   "source": [
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>BIO</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>guanfacine</td>\n",
       "      <td>B</td>\n",
       "      <td>DRUGS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>,</td>\n",
       "      <td>O</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>capecitabine</td>\n",
       "      <td>O</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>,</td>\n",
       "      <td>O</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ertapenem</td>\n",
       "      <td>B</td>\n",
       "      <td>DRUGS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           word BIO    tag\n",
       "0    guanfacine   B  DRUGS\n",
       "1             ,   O       \n",
       "2  capecitabine   O       \n",
       "3             ,   O       \n",
       "4     ertapenem   B  DRUGS"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame([(e.text, e.ent_iob_, e.ent_type_) for e in doc])\n",
    "df.columns = [\"word\",\"BIO\",\"tag\"]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_number</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>guanfacine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>capecitabine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>ertapenem</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_number          word\n",
       "0                0    guanfacine\n",
       "1                0             ,\n",
       "2                0  capecitabine\n",
       "3                0             ,\n",
       "4                0     ertapenem"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = []\n",
    "for sent_i, sent in enumerate(doc.sents):\n",
    "    for token in sent:\n",
    "        sentences.append((sent_i, token.text))\n",
    "        \n",
    "df2 = pd.DataFrame(sentences)\n",
    "df2.columns = [\"sentence_number\",\"word\"]\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           word BIO    tag  sentence_number\n",
      "0    guanfacine   B  DRUGS                0\n",
      "1             ,   O                       0\n",
      "2             ,   O                       0\n",
      "3             ,   O                       0\n",
      "4             ,   O                       0\n",
      "..          ...  ..    ...              ...\n",
      "157           .   O                       0\n",
      "158           I   O                       1\n",
      "159        have   O                       1\n",
      "160           a   O                       1\n",
      "161         cat   O                       1\n",
      "\n",
      "[162 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "merged_df = pd.merge(df, df2, on='word')\n",
    "print(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
