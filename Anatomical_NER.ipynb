{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/Felflare/entity-recognition-datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def txt_reader(inpt_file):\n",
    "    f = open(inpt_file, \"r\")\n",
    "    tok_lst = []\n",
    "    label_lst = []\n",
    "    for ix, x in enumerate(f):\n",
    "        if x == '\\n':\n",
    "            tok_lst.append('')\n",
    "            label_lst.append('')\n",
    "            continue\n",
    "        line = x.split()\n",
    "        tok = line[0]\n",
    "        try:\n",
    "            label = line[-1]\n",
    "        except:\n",
    "            print(line, ix)\n",
    "        tok_lst.append(tok)\n",
    "        label_lst.append(label)\n",
    "    f.close()\n",
    "    d = {'token':tok_lst,'ner':label_lst}\n",
    "    df = pd.DataFrame(d, columns=['token','ner'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "AnEM_train = txt_reader(\"/Users/sdeshpande/Desktop/entity-recognition-datasets/data/AnEM/CONLL-format/data/AnEM.train\")\n",
    "AnEM_test = txt_reader(\"/Users/sdeshpande/Desktop/entity-recognition-datasets/data/AnEM/CONLL-format/data/AnEM.test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "AnEM_train = AnEM_train.replace(\"\",np.nan)\n",
    "AnEM_train.dropna(inplace = True)\n",
    "AnEM_train.columns = [\"word\", \"tag\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ventricular</td>\n",
       "      <td>B-Multi-tissue_structure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fibrillation</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>due</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>to</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>long</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           word                       tag\n",
       "0   Ventricular  B-Multi-tissue_structure\n",
       "1  fibrillation                         O\n",
       "2           due                         O\n",
       "3            to                         O\n",
       "4          long                         O"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AnEM_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71697, 2)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AnEM_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "AnEM_test = AnEM_test.replace(\"\",np.nan)\n",
    "AnEM_test.dropna(inplace = True)\n",
    "AnEM_test.columns = [\"word\", \"tag\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Histopathologic</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>examination</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>of</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rectal</td>\n",
       "      <td>B-Pathological_formation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              word                       tag\n",
       "0                [                         O\n",
       "1  Histopathologic                         O\n",
       "2      examination                         O\n",
       "3               of                         O\n",
       "4           rectal  B-Pathological_formation"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AnEM_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45939, 2)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AnEM_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(117636, 2)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AnEM_train = AnEM_train.append(AnEM_test, ignore_index=True)\n",
    "AnEM_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ventricular</td>\n",
       "      <td>B-Multi-tissue_structure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fibrillation</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>due</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>to</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>long</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           word                       tag\n",
       "0   Ventricular  B-Multi-tissue_structure\n",
       "1  fibrillation                         O\n",
       "2           due                         O\n",
       "3            to                         O\n",
       "4          long                         O"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AnEM_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = AnEM_train.word.tolist()\n",
    "doc = \" \".join(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sdeshpande/opt/anaconda3/lib/python3.8/site-packages/spacy/util.py:275: UserWarning: [W031] Model 'en_core_web_md' (2.2.5) requires spaCy v2.2 and is incompatible with the current spaCy version (2.3.2). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "import plac\n",
    "from spacy.lang.en import English\n",
    "from spacy.matcher import PhraseMatcher\n",
    "from spacy.tokens import Doc, Span, Token\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_number</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Ventricular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>fibrillation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>due</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>long</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_number          word\n",
       "0                0   Ventricular\n",
       "1                0  fibrillation\n",
       "2                0           due\n",
       "3                0            to\n",
       "4                0          long"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = []\n",
    "for sent_i, sent in enumerate(doc.sents):\n",
    "    for token in sent:\n",
    "        sentences.append((sent_i, token.text))\n",
    "        \n",
    "df2 = pd.DataFrame(sentences)\n",
    "df2.columns = [\"sentence_number\",\"word\"]\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "AnEM_train_merged = AnEM_train.merge(df2, left_index=True, right_index=True, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         word_x                       tag  sentence_number        word_y\n",
      "0   Ventricular  B-Multi-tissue_structure                0   Ventricular\n",
      "1  fibrillation                         O                0  fibrillation\n",
      "2           due                         O                0           due\n",
      "3            to                         O                0            to\n",
      "4          long                         O                0          long\n"
     ]
    }
   ],
   "source": [
    "print(AnEM_train_merged.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "AnEM_train_merged.drop([\"word_y\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "AnEM_train_merged.columns = [\"word\",\"tag\", \"Sentence #\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117636"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(AnEM_train_merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-Multi-tissue_structure',\n",
       " 'O',\n",
       " 'B-Organism_substance',\n",
       " 'B-Organism_subdivision',\n",
       " 'B-Organ',\n",
       " 'I-Multi-tissue_structure',\n",
       " 'B-Cellular_component',\n",
       " 'I-Cellular_component',\n",
       " 'B-Cell',\n",
       " 'I-Cell',\n",
       " 'B-Immaterial_anatomical_entity',\n",
       " 'B-Tissue',\n",
       " 'I-Tissue',\n",
       " 'B-Pathological_formation',\n",
       " 'B-Anatomical_system',\n",
       " 'I-Organism_substance',\n",
       " 'I-Anatomical_system',\n",
       " 'I-Pathological_formation',\n",
       " 'I-Immaterial_anatomical_entity',\n",
       " 'I-Organ',\n",
       " 'I-Organism_subdivision',\n",
       " 'B-Developing_anatomical_structure',\n",
       " 'I-Developing_anatomical_structure']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = list(AnEM_train_merged.tag.unique())\n",
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fd36b8fa880>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "sns.countplot(AnEM_train_merged.tag.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tags = len(tags)\n",
    "num_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_func = lambda s: [(w, t) for w, t in zip(s[\"word\"].values.tolist(), s[\"tag\"].values.tolist())]\n",
    "group = AnEM_train_merged.groupby(\"Sentence #\").apply(agg_func)\n",
    "lines = [s for s in group]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Ventricular', 'B-Multi-tissue_structure'),\n",
       " ('fibrillation', 'O'),\n",
       " ('due', 'O'),\n",
       " ('to', 'O'),\n",
       " ('long', 'O'),\n",
       " ('QT', 'O'),\n",
       " ('syndrome', 'O'),\n",
       " ('probably', 'O'),\n",
       " ('caused', 'O'),\n",
       " ('by', 'O'),\n",
       " ('clindamycin', 'O'),\n",
       " ('.', 'O')]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [[tokens[0] for tokens in line] for line in lines]\n",
    "tags = [[tokens[1] for tokens in line] for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fd4777417c0>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sen_lengths = [len(sent) for sent in sentences]\n",
    "plt.figure(figsize=(15, 5))\n",
    "sns.countplot(sen_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "from itertools import chain\n",
    "from collections import Counter\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 60\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101 0 100\n"
     ]
    }
   ],
   "source": [
    "# get the special tokens, it is required to use these while encoding in Field\n",
    "init_token = tokenizer.cls_token\n",
    "pad_token = tokenizer.pad_token\n",
    "unk_token = tokenizer.unk_token\n",
    "\n",
    "init_token_idx = tokenizer.convert_tokens_to_ids(init_token)\n",
    "pad_token_idx = tokenizer.convert_tokens_to_ids(pad_token)\n",
    "unk_token_idx = tokenizer.convert_tokens_to_ids(unk_token)\n",
    "\n",
    "print(init_token_idx, pad_token_idx, unk_token_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# limit the input tokens to max length - 1, [CLS] is the initial token\n",
    "def convert_to_id(tokens, tokenizer, max_input_length=MAX_LEN):\n",
    "    tokens = tokens[:max_input_length-1]\n",
    "    tokens = [init_token_idx] + tokenizer.convert_tokens_to_ids(tokens)\n",
    "    return tokens\n",
    "\n",
    "def cut_tags(tag, max_input_length=MAX_LEN):\n",
    "    tags = tag[:max_input_length-1]\n",
    "    return tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 95.3 ms, sys: 1.53 ms, total: 96.8 ms\n",
      "Wall time: 95.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sentences_ids = [convert_to_id(line, tokenizer) for line in sentences]\n",
    "tags = [cut_tags(tag) for tag in tags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([101, 100, 100, 1496, 1106, 1263, 100, 9318, 1930, 2416, 1118, 100, 119],\n",
       " ['B-Multi-tissue_structure',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O'])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_ids[0], tags[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary(object):\n",
    "    def __init__(self):\n",
    "        self.word2idx = {}\n",
    "        self.idx2word = {}\n",
    "        self.idx = 0\n",
    "\n",
    "    def add_word(self, word):\n",
    "        if not word in self.word2idx:\n",
    "            self.word2idx[word] = self.idx\n",
    "            self.idx2word[self.idx] = word\n",
    "            self.idx += 1\n",
    "\n",
    "    def __call__(self, word):\n",
    "        return self.word2idx[word]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(tags, threshold=5):\n",
    "    \"\"\"Build a simple vocabulary wrapper.\"\"\"\n",
    "    counter = Counter(chain(*tags))\n",
    "\n",
    "    # If the word frequency is less than 'threshold', then the word is discarded.\n",
    "    words = [word for word, cnt in counter.items() if cnt >= threshold]\n",
    "\n",
    "    # Create a vocab wrapper and add some special tokens.\n",
    "    vocab = Vocabulary()\n",
    "    vocab.add_word('<pad>')\n",
    "\n",
    "    # Add the words to the vocabulary.\n",
    "    for i, word in enumerate(words):\n",
    "        vocab.add_word(word)\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total vocabulary size: 24\n"
     ]
    }
   ],
   "source": [
    "tags_vocab = build_vocab(tags)\n",
    "print(\"Total vocabulary size: {}\".format(len(tags_vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_ids = [[tags_vocab('<pad>')] + [tags_vocab(t) for t in tag] for tag in tags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4828, 603, 604)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences, valid_sentences, train_tags, valid_tags = train_test_split(sentences_ids, tags_ids, test_size=0.2, random_state=42)\n",
    "valid_sentences, test_sentences, valid_tags, test_tags = train_test_split(valid_sentences, valid_tags, test_size=0.5, random_state=42)\n",
    "len(train_sentences), len(valid_sentences), len(test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NERDataset(data.Dataset):\n",
    "    def __init__(self, sentences, tags):\n",
    "        self.sentences = sentences\n",
    "        self.tags = tags\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        sentence = self.sentences[item]\n",
    "        tag = self.tags[item]\n",
    "\n",
    "        return torch.LongTensor(sentence), torch.LongTensor(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = NERDataset(train_sentences, train_tags)\n",
    "valid_dataset = NERDataset(valid_sentences, valid_tags)\n",
    "test_dataset = NERDataset(test_sentences, test_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([  101,  1826,   119,  2614,  2097, 11621,   100,  1105,  5625,  1104,\n",
      "         3368,  1146,   117,  1134,  1195,  1215,  1112,   170,   100,  4929,\n",
      "         1111,  2616,   118,  3767,   117,  1127,  2412,  1750,  1696,   117,\n",
      "         8080]), tensor([0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2]))\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset[0])\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(data):\n",
    "    data.sort(key=lambda x: len(x[0]), reverse=True)\n",
    "    sentences, tags = zip(*data)\n",
    "\n",
    "    # Merge questions (from tuple of 1D tensor to 2D tensor).\n",
    "    sent_lengths = [len(sent) for sent in sentences]\n",
    "    inputs = torch.zeros(len(sentences), max(sent_lengths)).long()\n",
    "    labels = torch.zeros(len(sentences), max(sent_lengths)).long()\n",
    "    \n",
    "    for i, (sent, lab) in enumerate(zip(sentences, tags)):\n",
    "        end = sent_lengths[i]\n",
    "        inputs[i, :end] = sent[:end]\n",
    "        labels[i, :end] = lab[:end]\n",
    "\n",
    "    return inputs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader = data.DataLoader(train_dataset, BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "valid_data_loader = data.DataLoader(valid_dataset, BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "test_data_loader = data.DataLoader(test_dataset, BATCH_SIZE, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 60]), torch.Size([64, 60]))"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = next(iter(train_data_loader))\n",
    "sample[0].shape, sample[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NERTagger(nn.Module):\n",
    "    def __init__(self, output_dim, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        # bert model\n",
    "        self.bert = BertModel.from_pretrained('bert-base-cased')\n",
    "        \n",
    "        # bert model hidden size\n",
    "        d_model = self.bert.config.to_dict()['hidden_size']\n",
    "        \n",
    "        # prediction layer\n",
    "        self.fc = nn.Linear(d_model, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, text):\n",
    "        # text => [batch_size, seq_len]\n",
    "\n",
    "        embedded = self.dropout(self.bert(text)[0])\n",
    "        # only take the outputs, pooled output is not required\n",
    "        # embedded => [batch_size, seq_len, d_model]\n",
    "\n",
    "        predictions = self.fc(self.dropout(embedded))\n",
    "        # predictions => [batch_size, seq_len, output_dim]\n",
    "\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c1ff73eebe645278e5fed682ad32f7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a82665307d746cc98b788dcb55dac9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=435779157.0, style=ProgressStyle(descri"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "OUTPUT_DIM = len(tags_vocab)\n",
    "DROPOUT = 0.4\n",
    "\n",
    "model = NERTagger(OUTPUT_DIM, DROPOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 108,328,728 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 5e-5\n",
    "TAG_PAD_IDX = tags_vocab('<pad>')\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = TAG_PAD_IDX).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, criterion, optimizer):\n",
    "    model.train()\n",
    "\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for batch in iterator:\n",
    "        text = batch[0].to(device)\n",
    "        tags = batch[1].to(device)\n",
    "        # text => [seq_len, batch_size]\n",
    "        # tags => [seq_len, batch_size]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        logits = model(text)\n",
    "        # logits => [batch_size, seq_len, output_dim]\n",
    "\n",
    "        logits = logits.view(-1, logits.shape[-1])\n",
    "        # logits => [batch_size * seq_len, output_dim]\n",
    "\n",
    "        tags = tags.view(-1)\n",
    "        # tags => [batch_size * seq_len]\n",
    "\n",
    "        loss = criterion(logits, tags)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    model.eval()\n",
    "\n",
    "    epoch_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            text = batch[0].to(device)\n",
    "            tags = batch[1].to(device)\n",
    "            # text => [batch_size, seq_len]\n",
    "            # tags => [batch_size, seq_len]\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            logits = model(text)\n",
    "            # logits => [batch_size, seq_len, output_dim]\n",
    "\n",
    "            logits = logits.view(-1, logits.shape[-1])\n",
    "            # logits => [batch_size * seq_len, output_dim]\n",
    "\n",
    "            tags = tags.view(-1)\n",
    "            # tags => [batch_size * seq_len]\n",
    "\n",
    "            loss = criterion(logits, tags)\n",
    "            epoch_loss += loss.item()\n",
    "    \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 11m 49s\n",
      "\tTrain Loss: 0.379 | Val. Loss: 0.264\n",
      "Epoch: 02 | Epoch Time: 9m 31s\n",
      "\tTrain Loss: 0.245 | Val. Loss: 0.171\n",
      "Epoch: 03 | Epoch Time: 9m 30s\n",
      "\tTrain Loss: 0.171 | Val. Loss: 0.161\n",
      "Epoch: 04 | Epoch Time: 9m 37s\n",
      "\tTrain Loss: 0.142 | Val. Loss: 0.137\n",
      "Epoch: 05 | Epoch Time: 9m 32s\n",
      "\tTrain Loss: 0.112 | Val. Loss: 0.126\n"
     ]
    }
   ],
   "source": [
    "#N_EPOCHS = 10\n",
    "N_EPOCHS = 5\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss = train(model, train_data_loader, criterion, optimizer)\n",
    "    valid_loss = evaluate(model, valid_data_loader, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'model.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Val. Loss: {valid_loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_metrics(iterator):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    fin_outputs = []\n",
    "    fin_targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            text = batch[0].to(device)\n",
    "            tags = batch[1].to(device)\n",
    "            # text => [seq_len, batch_size]\n",
    "            # tags => [seq_len, batch_size]\n",
    "\n",
    "            logits = model(text)\n",
    "            # logits => [seq_len, batch_size, output_dim]\n",
    "\n",
    "            predictions = logits.argmax(-1)\n",
    "\n",
    "            fin_outputs.extend(predictions.detach().cpu().numpy().tolist())\n",
    "            fin_targets.extend(tags.detach().cpu().numpy().tolist())\n",
    "\n",
    "    assert len(fin_outputs) == len(fin_targets)\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    trans_trg = mlb.fit_transform(fin_targets)\n",
    "    trans_pred = mlb.transform(fin_outputs)\n",
    "    print(trans_pred)\n",
    "\n",
    "    cf = metrics.classification_report(trans_trg, trans_pred)\n",
    "    print(cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cal_metrics(test_data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BiLSTM_CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "\n",
    "from itertools import chain\n",
    "from collections import Counter\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [['<START>'] + [tokens[0] for tokens in line] + ['<END>'] for line in lines]\n",
    "tags = [['<START>'] + [tokens[1] for tokens in line] + ['<END>'] for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = [[['<START']] + [['<START>'] + [ch for ch in word] + ['<END>'] for word in sent[1:-1]] + [['<END>']] for sent in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6035, 6035, 6035)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences), len(tags), len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<START>',\n",
       " 'Ventricular',\n",
       " 'fibrillation',\n",
       " 'due',\n",
       " 'to',\n",
       " 'long',\n",
       " 'QT',\n",
       " 'syndrome',\n",
       " 'probably',\n",
       " 'caused',\n",
       " 'by',\n",
       " 'clindamycin',\n",
       " '.',\n",
       " '<END>']"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['<START'],\n",
       " ['<START>', 'V', 'e', 'n', 't', 'r', 'i', 'c', 'u', 'l', 'a', 'r', '<END>'],\n",
       " ['<START>',\n",
       "  'f',\n",
       "  'i',\n",
       "  'b',\n",
       "  'r',\n",
       "  'i',\n",
       "  'l',\n",
       "  'l',\n",
       "  'a',\n",
       "  't',\n",
       "  'i',\n",
       "  'o',\n",
       "  'n',\n",
       "  '<END>'],\n",
       " ['<START>', 'd', 'u', 'e', '<END>'],\n",
       " ['<START>', 't', 'o', '<END>'],\n",
       " ['<START>', 'l', 'o', 'n', 'g', '<END>'],\n",
       " ['<START>', 'Q', 'T', '<END>'],\n",
       " ['<START>', 's', 'y', 'n', 'd', 'r', 'o', 'm', 'e', '<END>'],\n",
       " ['<START>', 'p', 'r', 'o', 'b', 'a', 'b', 'l', 'y', '<END>'],\n",
       " ['<START>', 'c', 'a', 'u', 's', 'e', 'd', '<END>'],\n",
       " ['<START>', 'b', 'y', '<END>'],\n",
       " ['<START>', 'c', 'l', 'i', 'n', 'd', 'a', 'm', 'y', 'c', 'i', 'n', '<END>'],\n",
       " ['<START>', '.', '<END>'],\n",
       " ['<END>']]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fd204a4b700>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sen_lengths = [len(sent) for sent in sentences]\n",
    "plt.figure(figsize=(15, 5))\n",
    "sns.countplot(sen_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fd363e2a7f0>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "char_lengths = [len(t) for char in chars for t in char]\n",
    "plt.figure(figsize=(15, 5))\n",
    "sns.countplot(char_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4828, 603, 604)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences, valid_sentences, train_tags, valid_tags, train_chars, valid_chars = train_test_split(sentences, tags, chars, test_size=0.2, random_state=42)\n",
    "valid_sentences, test_sentences, valid_tags, test_tags, valid_chars, test_chars = train_test_split(valid_sentences, valid_tags, valid_chars, test_size=0.5, random_state=42)\n",
    "len(train_sentences), len(valid_sentences), len(test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocab:\n",
    "    def __init__(self, word2id, id2word):\n",
    "        self.UNK = '<UNK>'\n",
    "        self.PAD = '<PAD>'\n",
    "        self.START = '<START>'\n",
    "        self.END = '<END>'\n",
    "        self.__word2id = word2id\n",
    "        self.__id2word = id2word\n",
    "\n",
    "    def get_word2id(self):\n",
    "        return self.__word2id\n",
    "\n",
    "    def get_id2word(self):\n",
    "        return self.__id2word\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        if self.UNK in self.__word2id:\n",
    "            return self.__word2id.get(item, self.__word2id[self.UNK])\n",
    "        return self.__word2id[item]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.__word2id)\n",
    "\n",
    "    def id2word(self, idx):\n",
    "        return self.__id2word[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(data, freq_cutoff=5, is_tags=False, is_chars=False):\n",
    "    if is_chars:\n",
    "        word_counts = Counter(chain(*chain(*train_chars[:10])))\n",
    "    else:\n",
    "        word_counts = Counter(chain(*data))\n",
    "    valid_words = [w for w, d in word_counts.items() if d >= freq_cutoff]\n",
    "    valid_words = sorted(valid_words, key=lambda x: word_counts[x], reverse=True)\n",
    "    valid_words += ['<PAD>']\n",
    "    word2id = {w: idx for idx, w in enumerate(valid_words)}\n",
    "    if not is_tags:\n",
    "        word2id['<UNK>'] = len(word2id)\n",
    "        valid_words += ['<UNK>']\n",
    "    return Vocab(word2id=word2id, id2word=valid_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_vocab = build_vocab(train_sentences)\n",
    "tags_vocab = build_vocab(train_tags, is_tags=True)\n",
    "chars_vocab = build_vocab(train_chars, is_chars=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2622, 26, 45)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words_vocab), len(tags_vocab), len(chars_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQ_LEN = 50\n",
    "MAX_WORD_LEN = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NERDataset(data.Dataset):\n",
    "    def __init__(self, sentences, tags, chars, max_seq_len, max_word_len):\n",
    "        self.sentences = sentences\n",
    "        self.tags = tags\n",
    "        self.characters = chars\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.max_word_len = max_word_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        sentence = self.sentences[item]\n",
    "        tag = self.tags[item]\n",
    "        chars = self.characters[item]\n",
    "        seq_len = len(sentence)\n",
    "\n",
    "        # convert the sentences and tags into numerical format\n",
    "        word_tokens = [words_vocab[word] for word in sentence]\n",
    "        tag_tokens = [tags_vocab[t] for t in tag]\n",
    "\n",
    "        char_seq = []\n",
    "        for word in chars:\n",
    "            word_len = len(word)\n",
    "            # truncate the word if it is greater than max_word_len\n",
    "            if word_len > self.max_word_len:\n",
    "                word = word[:self.max_word_len]\n",
    "            # pad the word if it less\n",
    "            else:\n",
    "                pad_length = self.max_word_len - word_len\n",
    "                word = word + [chars_vocab.PAD] * pad_length\n",
    "            \n",
    "            # convert the chars into numerical format\n",
    "            char_ids = []\n",
    "            for each_char in word: \n",
    "                char_ids.append(chars_vocab[each_char])\n",
    "            char_seq.append(char_ids)\n",
    "        \n",
    "        return torch.LongTensor(word_tokens), torch.LongTensor(char_seq), torch.LongTensor(tag_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = NERDataset(train_sentences, train_tags, train_chars, MAX_SEQ_LEN, MAX_WORD_LEN)\n",
    "valid_dataset = NERDataset(valid_sentences, valid_tags, valid_chars, MAX_SEQ_LEN, MAX_WORD_LEN)\n",
    "test_dataset = NERDataset(test_sentences, test_tags, test_chars, MAX_SEQ_LEN, MAX_WORD_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([   0, 1217,    2, 2621, 2621, 2162,  507,    7,  462,    5, 2621,  174,\n",
       "            3,   51,   74,   76,   28,   12, 1798,  581,   14,  817,    6, 2621,\n",
       "            3,   18,  897,  230,  214,    3,  758,    1]),\n",
       " tensor([[24, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43],\n",
       "         [ 1,  8,  2,  9, 25,  3, 11,  2,  8,  0, 43, 43, 43, 43, 43],\n",
       "         [ 1, 26,  0, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43],\n",
       "         [ 1, 37,  3, 14,  2,  0, 43, 43, 43, 43, 43, 43, 43, 43, 43],\n",
       "         [ 1,  8, 15,  2,  5,  6,  0, 43, 43, 43, 43, 43, 43, 43, 43],\n",
       "         [ 1,  7, 20,  6,  4,  3,  5,  3,  5, 21,  0, 43, 43, 43, 43],\n",
       "         [ 1, 32,  9, 27, 32,  0, 43, 43, 43, 43, 43, 43, 43, 43, 43],\n",
       "         [ 1,  4,  5, 12,  0, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43],\n",
       "         [ 1, 16,  9,  2, 44, 17,  2,  5, 11, 18,  0, 43, 43, 43, 43],\n",
       "         [ 1,  7, 16,  0, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43],\n",
       "         [ 1, 15,  3, 11, 38,  0, 43, 43, 43, 43, 43, 43, 43, 43, 43],\n",
       "         [ 1, 17, 15,  0, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43],\n",
       "         [ 1, 22,  0, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43],\n",
       "         [ 1, 19, 13,  3, 11, 13,  0, 43, 43, 43, 43, 43, 43, 43, 43],\n",
       "         [ 1, 19,  2,  0, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43],\n",
       "         [ 1, 17,  8,  2, 12,  0, 43, 43, 43, 43, 43, 43, 43, 43, 43],\n",
       "         [ 1,  4,  8,  0, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43],\n",
       "         [ 1,  4,  0, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43],\n",
       "         [ 1, 15,  9,  7, 44, 18,  0, 43, 43, 43, 43, 43, 43, 43, 43],\n",
       "         [ 1, 14,  2,  4,  8, 17,  9,  2,  0, 43, 43, 43, 43, 43, 43],\n",
       "         [ 1, 16,  7,  9,  0, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43],\n",
       "         [ 1, 11,  7,  8,  6,  0, 43, 43, 43, 43, 43, 43, 43, 43, 43],\n",
       "         [ 1, 30,  0, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43],\n",
       "         [ 1,  7, 15, 15,  7,  9,  6, 17,  5,  3,  6, 18,  0, 43, 43],\n",
       "         [ 1, 22,  0, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43],\n",
       "         [ 1, 19,  2,  9,  2,  0, 43, 43, 43, 43, 43, 43, 43, 43, 43],\n",
       "         [ 1, 21,  2,  5,  2,  9,  4, 10, 10, 18,  0, 43, 43, 43, 43],\n",
       "         [ 1, 10,  2,  8,  8,  0, 43, 43, 43, 43, 43, 43, 43, 43, 43],\n",
       "         [ 1,  3, 14, 15,  7,  9,  6,  4,  5,  6,  0, 43, 43, 43, 43],\n",
       "         [ 1, 22,  0, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43],\n",
       "         [ 1, 11,  7,  5,  8,  3,  8,  6,  2,  5,  6,  0, 43, 43, 43],\n",
       "         [ 0, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43, 43]]),\n",
       " tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 2]))"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(data):\n",
    "    data.sort(key=lambda x: len(x[0]), reverse=True)\n",
    "    sentences, words, tags = zip(*data)\n",
    "\n",
    "    # Merge questions (from tuple of 1D tensor to 2D tensor).\n",
    "    sent_lengths = [len(sent) for sent in sentences]\n",
    "    inputs = torch.zeros(len(sentences), max(sent_lengths)).long()\n",
    "    labels = torch.zeros(len(sentences), max(sent_lengths)).long()\n",
    "    chars = torch.zeros(len(sentences), max(sent_lengths), MAX_WORD_LEN).long()\n",
    "    for i, (sent, lab, ch) in enumerate(zip(sentences, tags, words)):\n",
    "        end = sent_lengths[i]\n",
    "        inputs[i, :end] = sent[:end]\n",
    "        labels[i, :end] = lab[:end]\n",
    "        chars[i, :end] = ch[:end]\n",
    "    return inputs, chars, labels, sent_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader = data.DataLoader(train_dataset, BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "valid_data_loader = data.DataLoader(valid_dataset, BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
    "test_data_loader = data.DataLoader(test_dataset, BATCH_SIZE, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = next(iter(train_data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 50]), torch.Size([64, 50, 15]), torch.Size([64, 50]), 64)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[0].shape, sample[1].shape, sample[2].shape, len(sample[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharBiLSTMCRF(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim, hid_dim, char_emb_dim, char_hid_dim, char_vocab_size, tag_vocab_size, sent_pad_token, tag_start_token, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.hid_dim = hid_dim\n",
    "        self.sent_pad_token = sent_pad_token\n",
    "        self.tag_start_token = tag_start_token\n",
    "        self.tag_vocab_size = tag_vocab_size\n",
    "\n",
    "        self.char_embedding = nn.Embedding(char_vocab_size, char_emb_dim, padding_idx=0)\n",
    "        self.char_lstm = nn.LSTM(char_emb_dim, char_hid_dim, bidirectional=True, batch_first=True)\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(\n",
    "            emb_dim + char_hid_dim,\n",
    "            hid_dim,\n",
    "            bidirectional=True,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.emission = nn.Linear(hid_dim * 2, tag_vocab_size)\n",
    "        self.transition = nn.Parameter(torch.rand(tag_vocab_size, tag_vocab_size))\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, sentences, lengths, words, tags):\n",
    "        # sentences => [batch_size, seq_len]\n",
    "        # lengths => [batch_size]\n",
    "        # words => [batch_size, seq_len, word_len]\n",
    "        # tags => [batch_size, seq_len]\n",
    "\n",
    "        char_final_hidden = []\n",
    "        for word in words:\n",
    "            # word => [seq_len, word_len]\n",
    "            char_embed = self.char_embedding(word)\n",
    "            char_embed = self.dropout(char_embed)\n",
    "            # char_embed => [seq_len, word_len, char_emb_dim]\n",
    "\n",
    "            _, (char_hidden, _) = self.char_lstm(char_embed)\n",
    "            # char_hidden => [2, seq_len, char_hid_dim]\n",
    "\n",
    "            # add the final forward and backward hidden states\n",
    "            char_combined = char_hidden[-1, :, :] + char_hidden[-2, :, :]\n",
    "            # char_combined => [seq_len, char_hid_dim]\n",
    "\n",
    "            char_final_hidden.append(char_combined)\n",
    "        \n",
    "        char_encoding = torch.stack(char_final_hidden)\n",
    "        # char_encoding => [batch_size, seq_len, char_hid_dim]\n",
    "\n",
    "        mask = (sentences != self.sent_pad_token).to(device)\n",
    "        # mask => [batch_size, seq_len]\n",
    "\n",
    "        embed = self.embedding(sentences)\n",
    "        embed = self.dropout(embed)\n",
    "        # embed => [batch_size, seq_len, emb_dim]\n",
    "\n",
    "        embed_with_char = torch.cat((embed, char_encoding), dim=-1)\n",
    "        # embed_with_char => [batch_size, seq_len, emb_dim + char_hid_dim]\n",
    "\n",
    "        packed_input = nn.utils.rnn.pack_padded_sequence(embed_with_char, lengths, batch_first=True)\n",
    "        packed_output, _ = self.lstm(packed_input)\n",
    "        outputs, _ = nn.utils.rnn.pad_packed_sequence(packed_output, batch_first=True)\n",
    "        # outputs => [batch_size, seq_len, hid_dim * 2]\n",
    "\n",
    "        combined = torch.cat((outputs[:, :, :self.hid_dim], outputs[:, :, self.hid_dim:]), dim=-1)\n",
    "        combined = self.dropout(combined)\n",
    "        # combined => [batch_size, seq_len, hid_dim * 2]\n",
    "\n",
    "        emission_scores = self.emission(combined)\n",
    "        # emission_scores => [batch_size, seq_len, tag_size]\n",
    "\n",
    "        loss = self.vitebri_loss(tags, mask, emission_scores)\n",
    "        # loss => [batch_size]\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def vitebri_loss(self, tags, mask, emit_scores):\n",
    "        # tags => [batch_size, seq_len]\n",
    "        # mask => [batch_size, seq_len]\n",
    "        # emit_scores => [batch_size, seq_len, tag_size]\n",
    "\n",
    "        batch_size, sent_len = tags.shape\n",
    "\n",
    "        # calculate the ground truth score\n",
    "        score = torch.gather(emit_scores, 2, tags.unsqueeze(2)).squeeze(2)\n",
    "        # emission scores of actual tags\n",
    "        # score => [batch_size, seq_len]\n",
    "\n",
    "        # add the transition scores to the emission scores\n",
    "        # ignore the start token tag score\n",
    "        score[:, 1:] += self.transition[tags[:, :-1], tags[:, 1:]]\n",
    "\n",
    "        # consider only the scores of actual tokens not the padded\n",
    "        gold_scores = (score * mask.type(torch.float)).sum(dim=1)\n",
    "        # gold_scores => [batch_size]\n",
    "\n",
    "        # calculate the scores of the partition (Z)\n",
    "        # tensor to hold the accumulated sequence scores at each time step\n",
    "        # at the inital time step score will be on dim=0\n",
    "        scores_upto_t = emit_scores[:, 0].unsqueeze(1)\n",
    "        # scores_upto_t => [batch_size, 1, tag_size]\n",
    "\n",
    "        for i in range(1, sent_len):\n",
    "            # get the current batch_size\n",
    "            batch_t = mask[:, i].sum()\n",
    "\n",
    "            # get the accumulated scores till now (only the current batch size)\n",
    "            scores_unpad = scores_upto_t[:batch_t]\n",
    "            # scores_unpad => [batch_t, 1, tag_size]\n",
    "\n",
    "            # add the transition scores for this time step\n",
    "            scores_with_trans = emit_scores[:batch_t, i].unsqueeze(1) + self.transition\n",
    "            # scores_with_trans => [batch_t, tag_size, tag_size]\n",
    "\n",
    "            # add to the accumulation\n",
    "            sum_scores = scores_unpad.transpose(1, 2) + scores_with_trans\n",
    "            # sum_scores => [batch_t, tag_size, tag_size]\n",
    "            \n",
    "            # apply the following to overcome the overflow problems\n",
    "            # since the exp(some_big_number) will cause issues \n",
    "            # log( exp(z_k)) = max(z) + log( exp(z_k - max(z)))\n",
    "            # log( exp(z_k)) = log( exp(z_k - c + c))\n",
    "            #                 = log( exp(z_k - c) * exp(c))\n",
    "            #                 = log( exp(z_k - c)) + log(exp(c))\n",
    "            #                 = log( exp(z_k - c)) + c\n",
    "            # by taking c as max(z)\n",
    "            # log( exp(z_k)) = max(z) + log( exp(z_k - max(z))) [log_sum_exp]\n",
    "            # get the maximum score of the current time step\n",
    "            max_t = sum_scores.max(dim=1)[0].unsqueeze(1)\n",
    "            # max_t => [batch_t, 1, tag_size]\n",
    "\n",
    "            sum_scores = sum_scores - max_t\n",
    "            # sum_scores => [batch_t, tag_size, tag_size]\n",
    "\n",
    "            scores_t = max_t + torch.logsumexp(sum_scores, dim=1).unsqueeze(1)\n",
    "            # scores_t => [batch_t, 1, tag_size]\n",
    "\n",
    "            # update the accumulation scores\n",
    "            scores_upto_t = torch.cat((scores_t, scores_upto_t[batch_t:]), dim=0)\n",
    "            # scores_upto_t => [batch_size, 1, tag_size]\n",
    "        \n",
    "        final_scores = scores_upto_t.squeeze(1)\n",
    "        # final_scores => [batch_size, tag_size]\n",
    "\n",
    "        max_final_scores = final_scores.max(dim=-1)[0]\n",
    "        # max_final_scores => [batch_size]\n",
    "\n",
    "        predicted_scores = max_final_scores + torch.logsumexp(final_scores - max_final_scores.unsqueeze(1), dim=1)\n",
    "        # predicted_scores => [batch_size]\n",
    "\n",
    "        vitebri_loss = predicted_scores - gold_scores\n",
    "        # vitebri_loss => [batch_size]\n",
    "\n",
    "        return vitebri_loss\n",
    "    \n",
    "    def predict(self, sentences, lengths, words):\n",
    "        # sentences => [batch_size, seq_len]\n",
    "        # lengths => [batch_size]\n",
    "        # words => [batch_size, seq_len, word_len]\n",
    "\n",
    "        batch_size = sentences.size(0)\n",
    "\n",
    "        char_final_hidden = []\n",
    "        for word in words:\n",
    "            # word => [seq_len, word_len]\n",
    "            char_embed = self.char_embedding(word)\n",
    "            char_embed = self.dropout(char_embed)\n",
    "            # char_embed => [seq_len, word_len, char_emb_dim]\n",
    "\n",
    "            _, (char_hidden, _) = self.char_lstm(char_embed)\n",
    "            # char_hidden => [2, seq_len, char_hid_dim]\n",
    "\n",
    "            # add the final forward and backward hidden states\n",
    "            char_combined = char_hidden[-1, :, :] + char_hidden[-2, :, :]\n",
    "            # char_combined => [seq_len, char_hid_dim]\n",
    "\n",
    "            char_final_hidden.append(char_combined)\n",
    "        \n",
    "        char_encoding = torch.stack(char_final_hidden)\n",
    "        # char_encoding => [batch_size, seq_len, char_hid_dim]\n",
    "\n",
    "        mask = (sentences != self.sent_pad_token).to(device)\n",
    "        # mask => [batch_size, seq_len]\n",
    "\n",
    "        embed = self.embedding(sentences)\n",
    "        embed = self.dropout(embed)\n",
    "        # embed => [batch_size, seq_len, emb_dim]\n",
    "\n",
    "        embed_with_char = torch.cat((embed, char_encoding), dim=-1)\n",
    "        # embed_with_char => [batch_size, seq_len, emb_dim + char_hid_dim]\n",
    "\n",
    "        packed_inp = nn.utils.rnn.pack_padded_sequence(embed_with_char, lengths, batch_first=True)\n",
    "        packed_output, _ = self.lstm(packed_inp)\n",
    "        outputs, _ = nn.utils.rnn.pad_packed_sequence(packed_output, batch_first=True)\n",
    "        # outputs => [batch_size, seq_len, hid_dim * 2]\n",
    "\n",
    "        combined = torch.cat((outputs[:, :, :self.hid_dim], outputs[:, :, self.hid_dim:]), dim=-1)\n",
    "        combined = self.dropout(combined)\n",
    "        # combined => [batch_size, seq_len, hid_dim * 2]\n",
    "\n",
    "        emission_scores = self.emission(combined)\n",
    "        # emission_scores => [batch_size, seq_len, tag_size]\n",
    "\n",
    "        # to store the tags predicted at each time step\n",
    "        # since at the begining every tag is start tag create the list with start tags\n",
    "        tags = [[[self.tag_start_token] for _ in range(self.tag_vocab_size)]] * batch_size\n",
    "        # tags => [batch_size, tag_size, 1]\n",
    "\n",
    "        scores_upto_t = emission_scores[:, 0].unsqueeze(1)\n",
    "        # scores_upto_t => [batch_size, 1, tag_size]\n",
    "\n",
    "        for i in range(1, max(lengths)):\n",
    "            # get the current batch_size\n",
    "            batch_t = mask[:, i].sum()\n",
    "\n",
    "            # get the accumulated scores till now (only the current batch size)\n",
    "            scores_unpad = scores_upto_t[:batch_t]\n",
    "            # scores_unpad => [batch_t, 1, tag_size]\n",
    "\n",
    "            # add the transition scores for this time step\n",
    "            scores_with_trans = emission_scores[:batch_t, i].unsqueeze(1) + self.transition\n",
    "            # scores_with_trans => [batch_t, tag_size, tag_size]\n",
    "\n",
    "            # add to the accumulation\n",
    "            sum_scores = scores_unpad.transpose(1, 2) + scores_with_trans\n",
    "            # sum_scores => [batch_t, tag_size, tag_size]\n",
    "\n",
    "            max_scores_t, max_ids_t = torch.max(sum_scores, dim=1)\n",
    "            max_ids_t = max_ids_t.tolist()\n",
    "            # max_scores_t => [batch_t, tag_size]\n",
    "            # max_ids_t => [batch_t, tag_size]\n",
    "\n",
    "            # add the current time step predicted tags \n",
    "            tags[:batch_t] = [[tags[b][k] + [j] for j, k in enumerate(max_ids_t[b])] for b in range(batch_t)]\n",
    "            \n",
    "            # update the accumulation scores\n",
    "            scores_upto_t = torch.cat((max_scores_t.unsqueeze(1), scores_upto_t[batch_t:]), dim=0)\n",
    "            # scores_upto_t => [batch_size, tag_size]\n",
    "\n",
    "        scores = scores_upto_t.squeeze(1)\n",
    "        # scores => [batch_size, tag_size]\n",
    "\n",
    "        _, max_ids = torch.max(scores, dim=1)\n",
    "        max_ids = max_ids.tolist()\n",
    "        # max_ids => [batch_size]\n",
    "\n",
    "        # tags => [batch_size, tag_size, seq_len]\n",
    "        tags = [tags[b][k] for b, k in enumerate(max_ids)]\n",
    "        # tags => [batch_size, seq_len]\n",
    "\n",
    "        return tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CharBiLSTMCRF(\n",
       "  (char_embedding): Embedding(45, 20, padding_idx=0)\n",
       "  (char_lstm): LSTM(20, 50, batch_first=True, bidirectional=True)\n",
       "  (embedding): Embedding(2622, 50, padding_idx=0)\n",
       "  (lstm): LSTM(100, 200, batch_first=True, bidirectional=True)\n",
       "  (emission): Linear(in_features=400, out_features=26, bias=True)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(words_vocab)\n",
    "sent_pad_token = words_vocab[words_vocab.PAD]\n",
    "tag_start_token = tags_vocab[tags_vocab.START]\n",
    "emb_dim = 50\n",
    "hid_dim = 200\n",
    "char_emb_dim = 20\n",
    "char_hid_dim = 50\n",
    "char_vocab_size = len(chars_vocab)\n",
    "tag_vocab_size = len(tags_vocab)\n",
    "model = CharBiLSTMCRF(\n",
    "    vocab_size,\n",
    "    emb_dim,\n",
    "    hid_dim,\n",
    "    char_emb_dim,\n",
    "    char_hid_dim,\n",
    "    char_vocab_size,\n",
    "    tag_vocab_size,\n",
    "    sent_pad_token,\n",
    "    tag_start_token\n",
    ")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 655,102 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, clip):\n",
    "    model.train()\n",
    "\n",
    "    epoch_loss = 0\n",
    "    total_sentences = 0\n",
    "\n",
    "    for batch in iterator:\n",
    "        sentences = batch[0].to(device)\n",
    "        words = batch[1].to(device)\n",
    "        tags = batch[2].to(device)\n",
    "        seq_lengths = batch[3]\n",
    "        # sentences => [batch_size, seq_len]\n",
    "        # words => [batch_size, seq_len, word_len]\n",
    "        # tags => [batch_size, seq_len]\n",
    "        # seq_lengths => [batch_size]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        batch_loss = model(sentences, seq_lengths, words, tags)\n",
    "        # batch_loss => [batch_size]\n",
    "\n",
    "        loss = batch_loss.mean()\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += batch_loss.sum().item()\n",
    "        total_sentences += len(sentences)\n",
    "\n",
    "    return epoch_loss / total_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    total_sentences = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            sentences = batch[0].to(device)\n",
    "            words = batch[1].to(device)\n",
    "            tags = batch[2].to(device)\n",
    "            seq_lengths = batch[3]\n",
    "            # sentences => [batch_size, seq_len]\n",
    "            # words => [batch_size, seq_len, word_len]\n",
    "            # tags => [batch_size, seq_len]\n",
    "            # seq_lengths => [batch_size]\n",
    "\n",
    "            batch_loss = model(sentences, seq_lengths, words, tags)\n",
    "            # batch_loss => [batch_size]\n",
    "\n",
    "            loss = batch_loss.mean()\n",
    "\n",
    "            epoch_loss += batch_loss.sum().item()\n",
    "            total_sentences += len(sentences)\n",
    "        \n",
    "    return epoch_loss / total_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 1m 24s\n",
      "\tTrain Loss: 80.658 | Val. Loss: 20.857\n",
      "Epoch: 02 | Epoch Time: 1m 27s\n",
      "\tTrain Loss: 5.584 | Val. Loss: 2.295\n",
      "Epoch: 03 | Epoch Time: 1m 25s\n",
      "\tTrain Loss: 1.860 | Val. Loss: 1.641\n",
      "Epoch: 04 | Epoch Time: 1m 25s\n",
      "\tTrain Loss: 1.417 | Val. Loss: 1.556\n",
      "Epoch: 05 | Epoch Time: 1m 26s\n",
      "\tTrain Loss: 1.247 | Val. Loss: 1.429\n",
      "Epoch: 06 | Epoch Time: 1m 25s\n",
      "\tTrain Loss: 1.067 | Val. Loss: 1.380\n",
      "Epoch: 07 | Epoch Time: 1m 26s\n",
      "\tTrain Loss: 0.943 | Val. Loss: 1.342\n",
      "Epoch: 08 | Epoch Time: 1m 24s\n",
      "\tTrain Loss: 0.862 | Val. Loss: 1.392\n",
      "Epoch: 09 | Epoch Time: 1m 25s\n",
      "\tTrain Loss: 0.770 | Val. Loss: 1.301\n",
      "Epoch: 10 | Epoch Time: 1m 20s\n",
      "\tTrain Loss: 0.680 | Val. Loss: 1.371\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 10\n",
    "CLIP = 2\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss = train(model, train_data_loader, optimizer, CLIP)\n",
    "    valid_loss = evaluate(model, valid_data_loader)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'model.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Val. Loss: {valid_loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.589\n"
     ]
    }
   ],
   "source": [
    "test_loss = evaluate(model, test_data_loader)\n",
    "print(f'Test Loss: {test_loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_metrics(model, iterator):\n",
    "    model.eval()\n",
    "\n",
    "    fin_outputs = []\n",
    "    fin_targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            sentences = batch[0].to(device)\n",
    "            words = batch[1].to(device)\n",
    "            tags = batch[2].to(device)\n",
    "            seq_lengths = batch[3]\n",
    "            # sentences => [batch_size, seq_len]\n",
    "            # words => [batch_size, seq_len, word_len]\n",
    "            # tags => [batch_size, seq_len]\n",
    "            # seq_lengths => [batch_size]\n",
    "\n",
    "            predictions = model.predict(sentences, seq_lengths, words)\n",
    "            # predictions => [batch_size, seq_len]\n",
    "\n",
    "            fin_outputs.extend(predictions)\n",
    "            fin_targets.extend(tags.detach().cpu().numpy().tolist())\n",
    "        \n",
    "    assert len(fin_outputs) == len(fin_targets)\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    trans_trg = mlb.fit_transform(fin_targets)\n",
    "    trans_pred = mlb.transform(fin_outputs)\n",
    "\n",
    "    cf = metrics.classification_report(trans_trg, trans_pred)\n",
    "    print(cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       604\n",
      "           1       1.00      1.00      1.00       604\n",
      "           2       1.00      1.00      1.00       604\n",
      "           3       0.91      0.88      0.90        49\n",
      "           4       0.63      0.80      0.70        54\n",
      "           5       0.87      0.91      0.89        22\n",
      "           6       0.57      0.75      0.65        28\n",
      "           7       1.00      0.81      0.89        36\n",
      "           8       0.96      0.71      0.81        34\n",
      "           9       0.95      0.75      0.84        24\n",
      "          10       0.89      0.74      0.81        23\n",
      "          11       0.88      0.44      0.58        16\n",
      "          12       1.00      0.57      0.73        14\n",
      "          13       0.67      0.55      0.60        11\n",
      "          14       1.00      0.67      0.80         9\n",
      "          15       0.60      0.50      0.55         6\n",
      "          16       1.00      0.62      0.77         8\n",
      "          17       0.75      0.50      0.60         6\n",
      "          18       0.67      0.67      0.67         3\n",
      "          19       1.00      0.33      0.50         6\n",
      "          20       1.00      0.67      0.80         3\n",
      "          21       0.67      0.67      0.67         3\n",
      "          22       0.50      0.50      0.50         2\n",
      "          23       0.00      0.00      0.00         2\n",
      "\n",
      "   micro avg       0.97      0.96      0.96      2171\n",
      "   macro avg       0.81      0.67      0.72      2171\n",
      "weighted avg       0.97      0.96      0.96      2171\n",
      " samples avg       0.98      0.97      0.97      2171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cal_metrics(model, test_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(sentence):\n",
    "    if isinstance(sentence, str):\n",
    "        tokens = [words_vocab[words_vocab.START]] + sentence.split() + [words_vocab[words_vocab.END]]\n",
    "    else:\n",
    "        tokens = sentence\n",
    "    \n",
    "    chars = [['<START']] + [['<START>'] + [ch for ch in word] + ['<END>'] for word in tokens[1:-1]] + [['<END>']]\n",
    "\n",
    "    char_seq = []\n",
    "    for word in chars:\n",
    "        word_len = len(word)\n",
    "        # truncate the word if it is greater than max_word_len\n",
    "        if word_len > MAX_WORD_LEN:\n",
    "            word = word[:MAX_WORD_LEN]\n",
    "        # pad the word if it less\n",
    "        else:\n",
    "            pad_length = MAX_WORD_LEN - word_len\n",
    "            word = word + [chars_vocab.PAD] * pad_length\n",
    "        \n",
    "        # convert the chars into numerical format\n",
    "        char_ids = []\n",
    "        for each_char in word: \n",
    "            char_ids.append(chars_vocab[each_char])\n",
    "        char_seq.append(char_ids)\n",
    "\n",
    "    # numericalize\n",
    "    token_ids = [words_vocab[tok] for tok in tokens]\n",
    "    \n",
    "    # seq length\n",
    "    sent_length = [len(token_ids)]\n",
    "\n",
    "    # create tensors\n",
    "    sent_tensor = torch.LongTensor(token_ids).to(device)\n",
    "    sent_tensor = sent_tensor.unsqueeze(0)\n",
    "    # sent_tensor => [1, seq_len]\n",
    "\n",
    "    char_tensor = torch.LongTensor(char_seq).to(device)\n",
    "    char_tensor = char_tensor.unsqueeze(0)\n",
    "    # char_tensor => [1, seq_len, word_len]\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        predictions = model.predict(sent_tensor, sent_length, char_tensor)\n",
    "    \n",
    "    predictions = predictions[0]\n",
    "    predicted_tags = []\n",
    "    for i in predictions:\n",
    "        predicted_tags.append(tags_vocab.id2word(i))\n",
    "    \n",
    "    return tokens, predicted_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred. Tag\tActual Tag\tCorrect?\tToken\n",
      "\n",
      "<START>\t\t<START>\t\t\t\t<START>\n",
      "O\t\tO\t\t\t\tDeveloping\n",
      "O\t\tO\t\t\t\tsmall\n",
      "O\t\tO\t\t\t\tmolecule\n",
      "O\t\tO\t\t\t\tagonistic\n",
      "O\t\tO\t\t\t\tligands\n",
      "O\t\tO\t\t\t\tfor\n",
      "O\t\tO\t\t\t\ttyrosine\n",
      "O\t\tO\t\t\t\tkinase\n",
      "O\t\tO\t\t\t\treceptors\n",
      "O\t\tO\t\t\t\thas\n",
      "O\t\tO\t\t\t\tbeen\n",
      "O\t\tO\t\t\t\tdifficult\n",
      "O\t\tO\t\t\t\t,\n",
      "O\t\tO\t\t\t\tand\n",
      "O\t\tO\t\t\t\tit\n",
      "O\t\tO\t\t\t\tis\n",
      "O\t\tO\t\t\t\tgenerally\n",
      "O\t\tO\t\t\t\tthought\n",
      "O\t\tO\t\t\t\tthat\n",
      "O\t\tO\t\t\t\tsuch\n",
      "O\t\tO\t\t\t\tligands\n",
      "O\t\tO\t\t\t\trequire\n",
      "O\t\tO\t\t\t\tbivalency\n",
      "O\t\tO\t\t\t\t.\n",
      "<END>\t\t<END>\t\t\t\t<END>\n"
     ]
    }
   ],
   "source": [
    "sentence = test_sentences[0]\n",
    "actual_tags = test_tags[0]\n",
    "tokens, predicted_tag_ids = inference(sentence)\n",
    "\n",
    "print(\"Pred. Tag\\tActual Tag\\tCorrect?\\tToken\\n\")\n",
    "for token, pred_tag, actual_tag in zip(tokens, predicted_tag_ids, actual_tags):\n",
    "    correct = '' if pred_tag == actual_tag else ''\n",
    "    print(f\"{pred_tag}\\t\\t{actual_tag}\\t\\t{correct}\\t\\t{token}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred. Tag\tActual Tag\tCorrect?\tToken\n",
      "\n",
      "<START>\t\t<START>\t\t\t\t<START>\n",
      "O\t\tO\t\t\t\tnewborn\n",
      "O\t\tO\t\t\t\tpigs\n",
      "O\t\tO\t\t\t\t.\n",
      "O\t\tO\t\t\t\tTo\n",
      "O\t\tO\t\t\t\tinvestigate\n",
      "O\t\tO\t\t\t\tthe\n",
      "O\t\tO\t\t\t\tpotential\n",
      "O\t\tO\t\t\t\trole\n",
      "O\t\tO\t\t\t\tof\n",
      "O\t\tO\t\t\t\tsympathetic\n",
      "O\t\tB-Multi-tissue_structure\t\t\t\tnerves\n",
      "O\t\tO\t\t\t\tin\n",
      "O\t\tO\t\t\t\tpreventing\n",
      "O\t\tO\t\t\t\tpronounced\n",
      "O\t\tO\t\t\t\tincreases\n",
      "O\t\tO\t\t\t\tin\n",
      "B-Organ\t\tB-Organ\t\t\t\tcerebral\n",
      "B-Organism_substance\t\tB-Organism_substance\t\t\t\tblood\n",
      "<END>\t\t<END>\t\t\t\t<END>\n"
     ]
    }
   ],
   "source": [
    "sentence = test_sentences[10]\n",
    "actual_tags = test_tags[10]\n",
    "tokens, predicted_tag_ids = inference(sentence)\n",
    "\n",
    "print(\"Pred. Tag\\tActual Tag\\tCorrect?\\tToken\\n\")\n",
    "for token, pred_tag, actual_tag in zip(tokens, predicted_tag_ids, actual_tags):\n",
    "    correct = '' if pred_tag == actual_tag else ''\n",
    "    print(f\"{pred_tag}\\t\\t{actual_tag}\\t\\t{correct}\\t\\t{token}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred. Tag\tToken\n",
      "\n",
      "O\t\tVibrissae\n",
      "O\t\tare\n",
      "O\t\ttactile\n",
      "O\t\thairs\n",
      "O\t\tfound\n",
      "O\t\tmainly\n",
      "O\t\ton\n",
      "O\t\tthe\n",
      "B-Multi-tissue_structure\t\trostrum\n",
      "O\t\tof\n",
      "O\t\tmost\n",
      "O\t\tmammals.\n",
      "O\t\tThe\n",
      "O\t\tfollicle,\n",
      "O\t\twhich\n",
      "O\t\tis\n",
      "O\t\tsurrounded\n",
      "O\t\tby\n",
      "O\t\ta\n",
      "O\t\tlarge\n",
      "B-Multi-tissue_structure\t\tvenous\n",
      "O\t\tsinus,\n",
      "O\t\tis\n",
      "O\t\tcalled\n",
      "O\t\t'folliclesinus\n",
      "O\t\tcomplex'\n",
      "O\t\t(FSC).\n",
      "O\t\tThis\n",
      "O\t\tcomplex\n",
      "O\t\tis\n",
      "O\t\thighly\n",
      "O\t\tinnervated\n",
      "O\t\tby\n",
      "O\t\tsomatosensitive\n",
      "B-Organ\t\tfibers\n",
      "O\t\tand\n",
      "O\t\treached\n",
      "O\t\tby\n",
      "B-Tissue\t\tvisceromotor\n",
      "I-Tissue\t\tfibers\n",
      "O\t\tthat\n",
      "O\t\tinnervate\n",
      "O\t\tthe\n",
      "B-Multi-tissue_structure\t\tsurrounding\n",
      "I-Multi-tissue_structure\t\tvessels.\n",
      "O\t\tThe\n",
      "O\t\tsurrounding\n",
      "O\t\tstriated\n",
      "B-Tissue\t\tmuscles\n",
      "I-Tissue\t\treceive\n",
      "I-Tissue\t\tsomatomotor\n",
      "I-Tissue\t\tfibers\n",
      "O\t\tfrom\n",
      "O\t\tthe\n",
      "B-Multi-tissue_structure\t\tfacial\n",
      "I-Multi-tissue_structure\t\tnerve.\n",
      "O\t\tThe\n",
      "O\t\tbottlenose\n",
      "O\t\tdolphin\n",
      "O\t\t(Tursiops\n",
      "O\t\ttruncatus),\n",
      "O\t\ta\n",
      "O\t\tfrequently\n",
      "O\t\tdescribed\n",
      "O\t\tmember\n",
      "O\t\tof\n",
      "O\t\tthe\n",
      "O\t\tdelphinid\n",
      "O\t\tfamily,\n",
      "O\t\tpossesses\n",
      "O\t\tthis\n",
      "B-Organ\t\torgan\n",
      "O\t\tonly\n",
      "O\t\tin\n",
      "O\t\tthe\n",
      "O\t\tpostnatal\n",
      "O\t\tperiod.\n",
      "O\t\tHowever,\n",
      "O\t\tinformation\n",
      "O\t\ton\n",
      "O\t\tthe\n",
      "O\t\tfunction\n",
      "O\t\tof\n",
      "O\t\tthe\n",
      "B-Cellular_component\t\tvibrissal\n",
      "I-Cellular_component\t\tcomplex\n",
      "O\t\tin\n",
      "O\t\tthis\n",
      "O\t\tlatter\n",
      "O\t\tspecies\n",
      "O\t\tis\n",
      "O\t\tscarce.\n",
      "O\t\tRecently,\n",
      "O\t\tpsychophysical\n",
      "O\t\texperiments\n",
      "O\t\ton\n",
      "O\t\tthe\n",
      "O\t\triverliving\n",
      "O\t\tGuiana\n",
      "O\t\tdolphin\n",
      "O\t\t(Sotalia\n",
      "O\t\tguianensis)\n",
      "O\t\trevealed\n",
      "O\t\tthat\n",
      "O\t\tthe\n",
      "O\t\tFSC\n",
      "O\t\tcould\n",
      "O\t\twork\n",
      "O\t\tas\n",
      "O\t\tan\n",
      "O\t\telectroreceptor\n",
      "O\t\tin\n",
      "O\t\tmurky\n",
      "O\t\twaters.\n",
      "O\t\tIn\n",
      "O\t\tthe\n",
      "O\t\tpresent\n",
      "O\t\tstudy,\n",
      "O\t\twe\n",
      "O\t\tanalyzed\n",
      "O\t\tthe\n",
      "O\t\tmorphology\n",
      "O\t\tand\n",
      "O\t\tinnervation\n",
      "O\t\tof\n",
      "O\t\tthe\n",
      "O\t\tFSC\n",
      "O\t\tof\n",
      "O\t\tnewborn\n",
      "O\t\t(n\n",
      "O\t\t=\n",
      "O\t\t8)\n",
      "O\t\tand\n",
      "O\t\tadult\n",
      "O\t\t(n\n",
      "O\t\t=\n",
      "O\t\t3)\n",
      "O\t\tbottlenose\n",
      "O\t\tdolphins.\n",
      "O\t\tWe\n",
      "O\t\tused\n",
      "O\t\tMasson's\n",
      "O\t\ttrichrome\n",
      "O\t\tstain\n",
      "O\t\tand\n",
      "O\t\tantibodies\n",
      "O\t\tagainst\n",
      "O\t\tneurofilament\n",
      "O\t\t200\n",
      "O\t\tkDa\n",
      "O\t\t(NF\n",
      "O\t\t200),\n",
      "O\t\tprotein\n",
      "O\t\tgene\n",
      "O\t\tproduct\n",
      "O\t\t(PGP\n",
      "O\t\t9.5),\n",
      "O\t\tsubstance\n",
      "O\t\tP\n",
      "O\t\t(SP),\n",
      "O\t\tcalcitonin\n",
      "O\t\tgenerelated\n",
      "O\t\tpeptide,\n",
      "O\t\tand\n",
      "O\t\ttyrosine\n",
      "O\t\thydroxylase\n",
      "O\t\t(TH)\n",
      "O\t\tto\n",
      "O\t\tcharacterize\n",
      "O\t\tthe\n",
      "O\t\tFSC\n",
      "O\t\tof\n",
      "O\t\tthe\n",
      "O\t\ttwo\n",
      "O\t\tage\n",
      "O\t\tclasses.\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Vibrissae are tactile hairs found mainly on the rostrum of most mammals. The follicle, which is surrounded by a large venous sinus, is called 'folliclesinus complex' (FSC). This complex is highly innervated by somatosensitive fibers and reached by visceromotor fibers that innervate the surrounding vessels. The surrounding striated muscles receive somatomotor fibers from the facial nerve. The bottlenose dolphin (Tursiops truncatus), a frequently described member of the delphinid family, possesses this organ only in the postnatal period. However, information on the function of the vibrissal complex in this latter species is scarce. Recently, psychophysical experiments on the riverliving Guiana dolphin (Sotalia guianensis) revealed that the FSC could work as an electroreceptor in murky waters. In the present study, we analyzed the morphology and innervation of the FSC of newborn (n = 8) and adult (n = 3) bottlenose dolphins. We used Masson's trichrome stain and antibodies against neurofilament 200 kDa (NF 200), protein gene product (PGP 9.5), substance P (SP), calcitonin generelated peptide, and tyrosine hydroxylase (TH) to characterize the FSC of the two age classes.\"\n",
    "tokens, predicted_tag_ids = inference(sentence)\n",
    "\n",
    "print(\"Pred. Tag\\tToken\\n\")\n",
    "for token, pred_tag in zip(tokens[1:-1], predicted_tag_ids[1:-1]):\n",
    "    print(f\"{pred_tag}\\t\\t{token}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
